<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>论文笔记-AdversarialDefense-李皓阳</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
svg[id^="mermaidChart"] { line-height: 1em; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
mark .md-meta { color: rgb(0, 0, 0); opacity: 0.3 !important; }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}


/**
 * NexT for Typora
 * Brought to you by Bill Chen || https://github.com/BillChen2K/typora-theme-next
 *
 * - Want code ligatures for JetBrains Mono?
 * - Search for `font-variant-ligatures: none;` and comment that line.
 *
 * - Want to change the font size in exported pdf?
 * - Change the variable `--export-font-size` below.
 **/

:root {
    --base-font-size: 16px;
    --highlight-color: rgb(0, 160, 160);
    --text-color: #333;
    --headings-color: #262a30;
    --export-font-size: 13px;
    --select-text-bg-color: #262a30;
    --select-text-font-color: #eee;
}

* {
    /* Disable ligatures */
    font-variant-ligatures: none;
}


/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

html,
body,
#write {
    color: var(--text-color);
    font-size: var(--base-font-size);
    background: #fcfcfc;
    font-family: Overpass, "GlowSansSC", "Helvetica Neue", "pingfang sc", "microsoft yahei", sans-serif;
    font-weight: 400;
    line-height: 1.15;
    -webkit-text-size-adjust: 100%;
    /* letter-spacing: -0.5px; */
}

h1,
h2,
h3,
h4,
h5,
h6 {
    color: var(--headings-color);
    font-weight: 700;
    line-height: 1.5;
    margin: 20px 0 15px
}

.CodeMirror pre {
    font-family: 'JetBrains Mono';
    font-size: 0.95em;
    line-height: 1.65em;
}

#write {
    max-width: 914px;
    text-align: justify;
}

#write>h1:first-child {
    margin-top: 1.75rem;
}

#write>h2:first-child {
    margin-top: 1.5rem;
}

#write>h3:first-child {
    margin-top: 1rem;
}

#write>h4:first-child {
    margin-top: 0.5rem;
}

h1 {
    font-size: 2.5em
}

h2 {
    font-size: 1.75 em
}

h3 {
    font-size: 1.45em
}

h4 {
    font-size: 1.25em
}

h5 {
    font-size: 1.1em
}

h6 {
    font-size: 1em;
    font-weight: bold
}

#write code {
    color: var(--highlight-color);
}

p {
    color: var(--text-color);
    line-height: 1.7rem;
    margin: 0 0 8px;
}

#write ul {
    line-height: 1.75rem;
    margin-block-start: 0.6em;
    margin-block-end: 0.6em;
}

#write ol li {
    line-height: 1.75rem;
    margin-block-start: 0.6em;
    margin-block-end: 0.6em;
}

u {
    text-decoration: none;
    border-bottom: 1px solid #999;
}

#write>h3.md-focus:before {
    left: -1.875rem;
    top: 0.5rem;
    padding: 2px;
}

#write>h4.md-focus:before {
    left: -1.875rem;
    top: 0.3125rem;
    padding: 2px;
}

#write>h5.md-focus:before {
    left: -1.875rem;
    top: 0.25rem;
    padding: 2px;
}

#write>h6.md-focus:before {
    left: -1.875rem;
    top: .125rem;
    padding: 2px;
}

@media screen and (max-width: 48em) {
    blockquote {
        margin-left: 1rem;
        margin-right: 0;
        padding: 0.5em;
    }
    /* .h1,
    h1 {
        font-size: 2.827rem;
    }
    .h2,
    h2 {
        font-size: 1.999rem;
    }
    .h3,
    h3 {
        font-size: 1.413rem;
    }
    .h4,
    h4 {
        font-size: 1.250rem;
    }
    .h5,
    h5 {
        font-size: 1.150rem;
    }
    .h6,
    h6 {
        font-size: 1rem;
    } */
}

a .md-def-url {
    color: #262a30;
}

a {
    color: var(--highlight-color);
    text-decoration: none;
    font-weight: bold;
    transition-duration: 0.5s;
}

a:hover {
    text-decoration: underline;
}

table {
    border-collapse: collapse;
    border-spacing: 0;
    font-size: 1em;
    margin: 0 0 20px;
    width: 100%;
}

table tr:nth-child(2n),
thead {
    background-color: #f9f9f9;
}

tbody tr:hover {
    background: #f5f5f5
}

caption,
td,
th {
    font-weight: 400;
    padding: 8px;
    text-align: left;
    vertical-align: middle
}

table tr th {
    border-bottom: 3px solid #ddd;
    font-weight: 700;
    padding-bottom: 10px;
    background-color: var(--bg-color);
}

td,
th {
    border: 1px solid #ddd;
}

th {
    font-weight: 700;
    padding-bottom: 10px
}

td {
    border-bottom-width: 1px
}


/* Inline Code */

code,
.md-fences {
    background: #eee;
    border-radius: 3px;
    color: #555;
    padding: 2px 4px;
    overflow-wrap: break-word;
    word-wrap: break-word;
    font-family: 'JetBrains Mono';
    font-size: 0.935em;
}


/* Code Blocks */

.md-fences {
    margin: 0 0 20px;
    font-size: 0.9em;
    line-height: 1.5em;
    padding: 0.4em 1em;
    padding-top: 0.4em;
}

.task-list {
    padding-left: 0;
}

.task-list-item {
    padding-left: 2rem;
}

.task-list-item input {
    top: 3px;
}

.task-list-item input {
    outline: none;
    margin-bottom: 0.5em;
}

.task-list-item input::before {
    content: "";
    display: inline-block;
    width: 1rem;
    height: 1rem;
    vertical-align: middle;
    text-align: center;
    border: 1px solid gray;
    background-color: #fdfdfd;
    margin-left: -0.1rem;
    margin-right: 0.1rem;
    margin-top: -0.9rem;
}

.task-list-item input:checked::before {
    padding-left: 0.125em;
    content: '✔';
    /*◘*/
    font-size: 0.8125rem;
    line-height: 0.9375rem;
    margin-top: -0.9rem;
}


/* Chrome 29+ */

@media screen and (-webkit-min-device-pixel-ratio:0) and (min-resolution:.001dpcm) {
    .task-list-item input:before {
        margin-top: -0.2rem;
    }
    .task-list-item input:checked:before,
    .task-list-item input[checked]:before {
        margin-top: -0.2rem;
    }
}

blockquote {
    border-left: 4px solid #ddd;
    color: #666;
    margin: 0;
    margin-bottom: 10px;
    margin-top: 10px;
    padding: 0 15px
}

blockquote p {
    color: #666
}

blockquote cite::before {
    content: '-';
    padding: 0 5px
}


/* #write pre.md-meta-block {
    min-height: 30px;
    background: #f8f8f8;
    padding: 1.5em;
    font-weight: 300;
    font-size: 1em;
    padding-bottom: 1.5em;
    padding-top: 3em;
    margin-top: -1.5em;
    color: #999;
    border-left: 1000px #f8f8f8 solid;
    margin-left: -1000px;
    border-right: 1000px #f8f8f8 solid;
    margin-right: -1000px;
    margin-bottom: 2em;
    font-size: 0.8em;
    line-height: 1.5em;
    font-family: 'JetBrains Mono';
} */

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f1f1f1;
    border: 0;
    border-radius: 3px;
    color: hsl(0, 0%, 53%);
    margin-top: 0 !important;
    margin-bottom: 2em;
    font-size: 0.8em;
    line-height: 1.5em;
    font-family: 'JetBrains Mono';
}

.MathJax_Display {
    font-size: 0.9em;
    margin-top: 0.5em;
    margin-bottom: 0;
}

p.mathjax-block,
.mathjax-block {
    padding-bottom: 0;
}

.mathjax-block>.code-tooltip {
    bottom: 5px;
    box-shadow: none;
}

.md-image>.md-meta {
    padding-left: 0.5em;
    padding-right: 0.5em;
}

.md-image>img {
    margin-top: 2px;
}

.md-image>.md-meta:first-of-type:before {
    padding-left: 4px;
}

#typora-source {
    color: #555;
}


/** ui for windows **/

#md-searchpanel {
    border-bottom: 1px solid #ccc;
}

#md-searchpanel .btn {
    border: 1px solid #ccc;
}

#md-notification:before {
    top: 14px;
}

#md-notification {
    background: #eee;
}

.megamenu-menu-panel .btn {
    border: 1px solid #ccc;
}

#write>h3.md-focus:before {
    left: -1.5625rem;
    top: .375rem;
}

#write>h4.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h5.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h6.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

.md-image>.md-meta {
    border-radius: 3px;
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: inherit;
}

.md-toc {
    margin-top: 20px;
    padding-bottom: 5px;
}

.sidebar-tabs {
    border-bottom: none;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #efefef;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}


/** focus mode */

.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

.file-tree-node {
    margin-top: 8px;
    margin-bottom: 8px;
}

.file-node-title {
    padding-top: 2px;
}

.outline-item {
    padding-top: 5px;
    padding-bottom: 5px;
    cursor: pointer;
}

/* 
.modal-footer .btn-default,
.modal-footer .btn-primary {
    border: 2px solid #222;
}



#md-searchpanel .btn:not(.close-btn):hover {
    background: #fff;
    border-color: #222;
    color: #222;
    -webkit-box-shadow: none;
    box-shadow: none;
}

#md-searchpanel .btn:not(.close-btn) {
    background: #222;
    border-color: #222;
    color: #fff;
    -webkit-box-shadow: none;
    box-shadow: none;
    transition-duration: .2s;
}

.searchpanel-search-option-btn {
    border-radius: 0px;
    border: 1px solid #222;
} */

/* Search panel & UI */

#md-searchpanel .btn {
    border: none;
}

#md-searchpanel input {
    box-shadow: none;
}

.searchpanel-search-option-btn {
    border-color: #aaa;
    border-radius: 0;
}

.modal-dialog .btn {
    background: #222;
    border-width: 2px;
    border-color: #222;
    border-radius: 0;
    color: #fff;
    display: inline-block;
    font-size: .875em;
    line-height: 2rem;
    padding: 0 20px;
    margin: 5px;
    text-decoration: none;
    transition-delay: 0s;
    transition-duration: .2s;
    transition-timing-function: ease-in-out
}

.modal-dialog .btn:hover {
    background: #eee;
    border-color: #222;
    color: #222;
}


/* Printing issue */

.typora-export * {
    -webkit-print-color-adjust: exact;
}

.typora-export p {
    font-size: var(--export-font-size) !important;
}

.typora-export li {
    font-size: var(--export-font-size);
    line-height: 2rem;
}

.typora-export #write {
    font-size: var(--export-font-size) !important;
}

table,
pre {
    page-break-inside: avoid;
}

pre {
    word-wrap: break-word;
}

hr {
    background-image: repeating-linear-gradient(-45deg, #ddd, #ddd 4px, transparent 4px, transparent 8px);
    border: 0;
    height: 3px;
    margin: 40px 0
}

 .typora-export li, .typora-export p, .typora-export,  .footnote-line {white-space: normal;} 
</style>
</head>
<body class='typora-export os-windows'>
<div id='write'  class=''><h1><a name="defenses-against-adversarial-attacks" class="md-header-anchor"></a><span>Defenses against Adversarial Attacks</span></h1><p><span>By LI Haoyang 2020.10.20 | 2020.11.15</span></p><h2><a name="content" class="md-header-anchor"></a><span>Content</span></h2><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n0"><a class="md-toc-inner" href="#defenses-against-adversarial-attacks">Defenses against Adversarial Attacks</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n3"><a class="md-toc-inner" href="#content">Content</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n5"><a class="md-toc-inner" href="#regularization">Regularization</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n15"><a class="md-toc-inner" href="#adversarial-training">Adversarial Training</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n41"><a class="md-toc-inner" href="#robust-structure">Robust Structure</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n46"><a class="md-toc-inner" href="#defense-at-inference">Defense at Inference</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n53"><a class="md-toc-inner" href="#ensemble">Ensemble</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n58"><a class="md-toc-inner" href="#breach">Breach</a></span></p></div><h2><a name="regularization" class="md-header-anchor"></a><span>Regularization</span></h2><p><span>There a bunch of methods trying to increase robustness of model by regularization. The idea of regularization germinated from the very first paper that proposed the problem of adversarial example, i.e. </span><em><span>Intriguing properties of neural networks</span></em><span>.</span></p><p><a href="Note-AdversarialRegularization.html" target="_blank"><span>Adversarial Defense by Regularization</span></a></p><ul><li><em><span>Moustapha Cisse , Piotr Bojanowski, Edouard Grave, Yann Dauphin, Nicolas Usunier. Parseval Networks: Improving Robustness to Adversarial Examples. ICML 2017. </span><strong><a href='https://arxiv.org/abs/1704.08847'><span> arXiv:1704.08847</span></a></strong></em></li><li><em><span>Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli. Adversarial robustness through local linearization. In NeurIPS, 2019. </span><strong><a href='https://arxiv.org/abs/1907.02610'><span> arXiv:1907.02610</span></a></strong></em></li><li><em><span>Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu. Jacobian Adversarially Regularized Networks for Robustness. ICLR 2020. </span><a href='https://arxiv.org/abs/1912.10185'><span> </span><strong><span>arXiv:1912.10185</span></strong></a></em></li></ul><h2><a name="adversarial-training" class="md-header-anchor"></a><span>Adversarial Training</span></h2><p><span>The prevailing method to defend adversarial attack is adversarial training, using the adversarial examples generated online to  train the model for a more robust version. It was proposed along with Fast Gradient Sign Method.</span></p><p><a href="Note-AdversarialTraining.html" target="_blank"><span>Adversarial Defense by Adversarial Training</span></a></p><ul><li><em><span>Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu. Towards Deep Learning Models Resistant to Adversarial Attacks. ICLR 2018. </span><strong><a href='https://arxiv.org/abs/1706.06083'><span> arXiv:1706.06083</span></a></strong></em></li><li><em><span>Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S. Davis, Gavin Taylor, Tom Goldstein. Adversarial Training for Free! </span><a href='https://arxiv.org/abs/1904.12843v2'><strong><span>arXiv:1904.12843v2</span></strong></a></em></li><li><em><span>Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong. You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle. NIPS 2019.</span></em><span> </span><strong><em><span>Paper: </span><a href='http://papers.nips.cc/paper/8316-you-only-propagate-once-accelerating-adversarial-training-via-maximal-principle' target='_blank' class='url'>http://papers.nips.cc/paper/8316-you-only-propagate-once-accelerating-adversarial-training-via-maximal-principle</a></em></strong></li><li><em><span>Jonathan Uesato, Jean-Baptiste Alayrac, Po-Sen Huang, Robert Stanforth, Alhussein Fawzi, Pushmeet Kohli. Are Labels Required for Improving Adversarial Robustness?. NIPS 2019. </span><a href='https://arxiv.org/abs/1905.13725'><span> </span><strong><span>arXiv:1905.13725</span></strong></a></em></li><li><em><span>Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli. Attacks Which Do Not Kill Training Make Adversarial Learning Stronger. ICML 2020. </span><a href='https://arxiv.org/abs/2002.11242'><strong><span>arXiv:2002.11242</span></strong></a></em></li><li><em><span>Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, Quoc V. Le. Smooth Adversarial Training. </span><strong><a href='https://arxiv.org/abs/2006.14536'><span>arXiv:2006.14536</span></a></strong></em></li><li><em><span>Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, Michael I. Jordan. Theoretically Principled Trade-off between Robustness and Accuracy. ICML 2019. </span><strong><a href='https://arxiv.org/abs/1901.08573'><span> arXiv:1901.08573</span></a></strong></em></li><li><em><span>Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan Yuille, Kaiming He. Feature Denoising for Improving Adversarial Robustness. CVPR 2019.  </span><a href='https://arxiv.org/abs/1812.03411'><span> </span><strong><span>arXiv:1812.03411</span></strong></a></em></li><li><em><span>Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better than free: Revisiting adversarial training. ICLR, 2020</span></em><span>. </span><strong><em><span>Paper: </span><a href='https://openreview.net/forum?id=BJx040EFvH&amp;noteId=BJx040EFvH' target='_blank' class='url'>https://openreview.net/forum?id=BJx040EFvH&noteId=BJx040EFvH</a></em></strong></li><li><em><span>Maksym Andriushchenko, Nicolas Flammarion. Understanding and Improving Fast Adversarial Training. NIPS 2020.</span></em><span> </span><strong><em><span>Paper: </span><a href='https://infoscience.epfl.ch/record/278914' target='_blank' class='url'>https://infoscience.epfl.ch/record/278914</a></em></strong></li><li><em><span>Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, Aleksander Madry. Adversarially Robust Generalization Requires More Data. NIPS 2018. </span><a href='https://arxiv.org/abs/1804.11285'><strong><span>arXiv:1804.11285</span></strong></a></em></li></ul><h2><a name="robust-structure" class="md-header-anchor"></a><span>Robust Structure</span></h2><p><a href="Note-AdversarialDefenseStructure.html" target="_blank"><span>Robust Structure</span></a></p><ul><li><em><span>Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin. When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks. CVPR 2020. </span><a href='https://arxiv.org/abs/1911.10695'><strong><span>arXiv:1911.10695</span></strong></a></em></li></ul><h2><a name="defense-at-inference" class="md-header-anchor"></a><span>Defense at Inference</span></h2><p><a href="Note-AdversarialDefenseInference.html" target="_blank"><span>Adversarial Defense at Inference</span></a></p><ul><li><em><span>Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, Nate Kushman. PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples. ICLR 2018. </span><strong><a href='https://arxiv.org/abs/1710.10766'><span> arXiv:1710.10766</span></a></strong></em></li><li><em><span>Tianyu Pang, Kun Xu, Jun Zhu.  Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks. ICLR 2020. </span><strong><span>Paper</span></strong><span>: </span><a href='https://openreview.net/forum?id=ByxtC2VtPB' target='_blank' class='url'>https://openreview.net/forum?id=ByxtC2VtPB</a></em></li></ul><h2><a name="ensemble" class="md-header-anchor"></a><span>Ensemble</span></h2><p><a href="Note-AdversarialDefenseEnsemble.html" target="_blank"><span>Adversarial Defense with Ensemble</span></a></p><ul><li><em><span>Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li. DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles. NIPS 2020. </span><a href='https://arxiv.org/abs/2009.14720'><span>arXiv:2009.14720</span></a></em></li></ul><h2><a name="breach" class="md-header-anchor"></a><span>Breach</span></h2><p><a href="Note-AdversarialDefenseBreach.html" target="_blank"><span>Breach Adversarial Defenses</span></a></p><ul><li><p><em><span>Nicholas Carlini, David Wagner. Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods. AISec 2017. </span><strong><a href='https://arxiv.org/abs/1705.07263'><span> arXiv:1705.07263</span></a></strong></em></p><p><span>Breached:</span></p><ul><li><p><em><span>Secondary classification based detection</span></em></p><ul><li><em><span>Zhitao Gong, Wenlu Wang, and Wei-Shinn Ku. 2017. Adversarial and Clean Data Are Not Twins. arXiv preprint arXiv:1704.04960 (2017).</span></em><span> (</span><strong><span>Adversarial Retraining</span></strong><span>)</span></li><li><em><span>Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, and Patrick McDaniel. 2017. On the (Statistical) Detection of Adversarial Examples. arXiv preprint arXiv:1702.06280 (2017).</span></em><span> (</span><strong><span>Adversarial Retraining</span></strong><span>)</span></li><li><em><span>Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff. 2017. On Detecting Adversarial Perturbations. In International Conference on Learning Representations. arXiv preprint arXiv:1702.04267.</span></em><span> (</span><strong><span>Examining Convolutional Layers</span></strong><span>)</span></li></ul></li><li><p><em><span>Principal component analysis detection</span></em></p><ul><li><em><span>Arjun Nitin Bhagoji, Daniel Cullina, and Prateek Mittal. 2017. Dimensionality Reduction as a Defense against Evasion Attacks on Machine Learning Classifiers. arXiv preprint arXiv:1704:02654 (2017).</span></em><span>(</span><strong><span>Dimensionality Reduction</span></strong><span>)</span></li><li><em><span>Dan Hendrycks and Kevin Gimpel. 2017. Early Methods for Detecting Adversarial Images. In International Conference on Learning Representations(WorkshopTrack).</span></em><span> (</span><strong><span>Input Image PCA</span></strong><span>)</span></li><li><em><span>Xin Li and Fuxin Li. 2016. Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics. arXiv preprint arXiv:1612.07767 (2016)</span></em><span> (</span><strong><span>Hidden Layer PCA</span></strong><span>)</span></li></ul></li><li><p><em><span>Distributional detection</span></em></p><ul><li><em><span>Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. 2017. Detecting Adversarial Samples from Artifacts. arXiv preprint arXiv:1703.00410 (2017).</span></em><span> (</span><strong><span>Kernel Density Estimation</span></strong><span>)</span></li><li><em><span>Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, and Patrick McDaniel. 2017. On the (Statistical) Detection of Adversarial Examples. arXiv preprint arXiv:1702.06280 (2017).</span></em><span> (</span><mark><span>Two methods proposed in one paper.</span></mark><span>) (</span><strong><span>Maximum Mean Discrepancy</span></strong><span>)</span></li></ul></li><li><p><em><span>Normalization detection</span></em></p><ul><li><em><span>Reuben Feinman, Ryan R Curtin, Saurabh Shintre, and Andrew B Gardner. 2017. Detecting Adversarial Samples from Artifacts. arXiv preprint arXiv:1703.00410 (2017).</span></em><span> (</span><mark><span>Two methods proposed in one paper</span></mark><span>) (</span><strong><span>Dropout Randomization</span></strong><span>)</span></li><li><em><span>Xin Li and Fuxin Li. 2016. Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics. arXiv preprint arXiv:1612.07767 (2016)</span></em><span> (</span><mark><span>Two methods proposed in one paper</span></mark><span>) (</span><strong><span>Mean Blur</span></strong><span>)</span></li></ul></li></ul></li><li><p><em><span>Warren He, James Wei, Xinyun Chen, Nicholas Carlini, Dawn Song. Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong. 2017. </span><strong><a href='https://arxiv.org/abs/1706.04701'><span> arXiv:1706.04701</span></a></strong></em></p><p><span>Breached:</span></p><ul><li><p><em><span>feature squeezing</span></em></p><ul><li><em><span>XU, W., EVANS, D., AND QI, Y. Feature squeezing: Detecting adversarial examples in deep neural networks. arXiv preprint arXiv:1704.01155 (2017).</span></em></li><li><em><span>XU, W., EVANS, D., AND QI, Y. Feature squeezing mitigates and detects Carlini/Wagner adversarial examples. arXiv preprint arXiv:1705.10686 (2017).</span></em></li></ul></li><li><p><em><span>specialists+1</span></em></p><ul><li><em><span>ABBASI, M., AND GAGN´E, C. Robustness to adversarial examples through an ensemble of specialists. arXiv preprint arXiv:1702.06856 (2017).</span></em></li></ul></li><li><p><em><span>ensemble of three detectors</span></em></p><ul><li><em><span>FEINMAN, R., CURTIN, R. R., SHINTRE, S., AND GARDNER, A. B. Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410 (2017)</span></em></li><li><em><span>GONG, Z., WANG, W., AND KU, W.-S. Adversarial and clean data are not twins. arXiv preprint arXiv:1704.04960 (2017).</span></em></li><li><em><span>METZEN, J. H., GENEWEIN, T., FISCHER, V., AND BISCHOFF, B. On detecting adversarial perturbations. arXiv preprint arXiv:1702.04267 (2017).</span></em></li></ul></li></ul></li><li><p><em><span>Anish Athalye, Nicholas Carlini, David Wagner. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. ICML 2018. </span><strong><a href='http://export.arxiv.org/abs/1802.00420'><span> arXiv:1802.00420</span></a></strong></em></p><p><span>Un-breached:</span></p><ul><li><p><em><span>Adversarial Training</span></em></p><ul><li><em><span>Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. Towards deep learning models resistant to adversarial attacks. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=rJzIBfZAb' target='_blank' class='url'>https://openreview.net/forum?id=rJzIBfZAb</a><span>. accepted as poster</span></em><span> (</span><strong><span>Adversarial Training with PGD</span></strong><span>)</span></li><li><em><span>Na, T., Ko, J. H., and Mukhopadhyay, S. Cascade adversarial machine learning regularized with a unified embedding. In International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=HyRVBzap-' target='_blank' class='url'>https://openreview.net/forum?id=HyRVBzap-</a><span>.</span></em><span> (</span><strong><span>Cascade Adversarial Training</span></strong><span>)</span></li></ul></li></ul><p><span>Breached:</span></p><ul><li><p><em><span>Gradient Shattering</span></em></p><ul><li><em><span>Jacob Buckman, Aurko Roy, Colin Raffel, Ian Goodfellow. Thermometer Encoding: One Hot Way To Resist Adversarial Examples. ICLR 2018. URL: </span><a href='https://openreview.net/forum?id=S18Su--CW' target='_blank' class='url'>https://openreview.net/forum?id=S18Su--CW</a></em><span> (</span><strong><span>Thermometer Encoding</span></strong><span>)</span></li><li><em><span>Guo, C., Rana, M., Cisse, M., and van der Maaten, L. Countering adversarial images using input transformations. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=SyJ7ClWCb' target='_blank' class='url'>https://openreview.net/forum?id=SyJ7ClWCb</a><span>. accepted as poster</span></em><span> (</span><strong><span>Input Transformations</span></strong><span>)</span></li><li><em><span>Ma, X., Li, B., Wang, Y., Erfani, S. M., Wijewickrema, S., Schoenebeck, G., Houle, M. E., Song, D., and Bailey, J. Characterizing adversarial subspaces using local intrinsic dimensionality. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=B1gJ1L2aW' target='_blank' class='url'>https://openreview.net/forum?id=B1gJ1L2aW</a><span>. accepted as oral presentation.</span></em><span> (</span><strong><span>Local Intrinsic Dimensionality</span></strong><span>)</span></li></ul></li><li><p><em><span>Stochastic Gradients</span></em></p><ul><li><em><span>Dhillon, G. S., Azizzadenesheli, K., Bernstein, J. D., Kossaifi, J., Khanna, A., Lipton, Z. C., and Anandkumar, A. Stochastic activation pruning for robust adversarial defense. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=H1uR4GZRZ' target='_blank' class='url'>https://openreview.net/forum?id=H1uR4GZRZ</a><span>. accepted as poster.</span></em><span> (</span><strong><span>Stochastic Activation Pruning</span></strong><span>)</span></li><li><em><span>Xie, C., Wang, J., Zhang, Z., Ren, Z., and Yuille, A. Mitigating adversarial effects through randomization. International Conference on Learning Representations,2018. URL </span><a href='https://openreview.net/forum?id=Sk9yuql0Z' target='_blank' class='url'>https://openreview.net/forum?id=Sk9yuql0Z</a><span>. accepted as poster.</span></em><span> (</span><strong><span>Mitigating Through Randomization</span></strong><span>)</span></li></ul></li><li><p><em><span>Vanishing &amp; Exploding Gradients</span></em></p><ul><li><em><span>Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N. Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=rJUYGxbCW' target='_blank' class='url'>https://openreview.net/forum?id=rJUYGxbCW</a><span>. accepted as poster.</span></em><span> (</span><strong><span>PixelDefend</span></strong><span>)</span></li><li><em><span>Samangouei, P., Kabkab, M., and Chellappa, R. Defensegan: Protecting classifiers against adversarial attacks using generative models. International Conference on Learning Representations, 2018. URL </span><a href='https://openreview.net/forum?id=BkJ3ibb0-' target='_blank' class='url'>https://openreview.net/forum?id=BkJ3ibb0-</a><span>. accepted as poster</span></em><span> (</span><strong><span>Defense-GAN</span></strong><span>)</span></li></ul></li></ul></li></ul><p>&nbsp;</p></div>
</body>
</html>