<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Landscape-AdversarialExample-李皓阳</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
svg[id^="mermaidChart"] { line-height: 1em; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
mark .md-meta { color: rgb(0, 0, 0); opacity: 0.3 !important; }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}


/**
 * NexT for Typora
 * Brought to you by Bill Chen || https://github.com/BillChen2K/typora-theme-next
 *
 * - Want code ligatures for JetBrains Mono?
 * - Search for `font-variant-ligatures: none;` and comment that line.
 *
 * - Want to change the font size in exported pdf?
 * - Change the variable `--export-font-size` below.
 **/

:root {
    --base-font-size: 16px;
    --highlight-color: rgb(0, 160, 160);
    --text-color: #333;
    --headings-color: #262a30;
    --export-font-size: 13px;
    --select-text-bg-color: #262a30;
    --select-text-font-color: #eee;
}

* {
    /* Disable ligatures */
    font-variant-ligatures: none;
}


/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

/* latin-ext */

/* latin */

html,
body,
#write {
    color: var(--text-color);
    font-size: var(--base-font-size);
    background: #fcfcfc;
    font-family: Overpass, "GlowSansSC", "Helvetica Neue", "pingfang sc", "microsoft yahei", sans-serif;
    font-weight: 400;
    line-height: 1.15;
    -webkit-text-size-adjust: 100%;
    /* letter-spacing: -0.5px; */
}

h1,
h2,
h3,
h4,
h5,
h6 {
    color: var(--headings-color);
    font-weight: 700;
    line-height: 1.5;
    margin: 20px 0 15px
}

.CodeMirror pre {
    font-family: 'JetBrains Mono';
    font-size: 0.95em;
    line-height: 1.65em;
}

#write {
    max-width: 914px;
    text-align: justify;
}

#write>h1:first-child {
    margin-top: 1.75rem;
}

#write>h2:first-child {
    margin-top: 1.5rem;
}

#write>h3:first-child {
    margin-top: 1rem;
}

#write>h4:first-child {
    margin-top: 0.5rem;
}

h1 {
    font-size: 2.5em
}

h2 {
    font-size: 1.75 em
}

h3 {
    font-size: 1.45em
}

h4 {
    font-size: 1.25em
}

h5 {
    font-size: 1.1em
}

h6 {
    font-size: 1em;
    font-weight: bold
}

#write code {
    color: var(--highlight-color);
}

p {
    color: var(--text-color);
    line-height: 1.7rem;
    margin: 0 0 8px;
}

#write ul {
    line-height: 1.75rem;
    margin-block-start: 0.6em;
    margin-block-end: 0.6em;
}

#write ol li {
    line-height: 1.75rem;
    margin-block-start: 0.6em;
    margin-block-end: 0.6em;
}

u {
    text-decoration: none;
    border-bottom: 1px solid #999;
}

#write>h3.md-focus:before {
    left: -1.875rem;
    top: 0.5rem;
    padding: 2px;
}

#write>h4.md-focus:before {
    left: -1.875rem;
    top: 0.3125rem;
    padding: 2px;
}

#write>h5.md-focus:before {
    left: -1.875rem;
    top: 0.25rem;
    padding: 2px;
}

#write>h6.md-focus:before {
    left: -1.875rem;
    top: .125rem;
    padding: 2px;
}

@media screen and (max-width: 48em) {
    blockquote {
        margin-left: 1rem;
        margin-right: 0;
        padding: 0.5em;
    }
    /* .h1,
    h1 {
        font-size: 2.827rem;
    }
    .h2,
    h2 {
        font-size: 1.999rem;
    }
    .h3,
    h3 {
        font-size: 1.413rem;
    }
    .h4,
    h4 {
        font-size: 1.250rem;
    }
    .h5,
    h5 {
        font-size: 1.150rem;
    }
    .h6,
    h6 {
        font-size: 1rem;
    } */
}

a .md-def-url {
    color: #262a30;
}

a {
    color: var(--highlight-color);
    text-decoration: none;
    font-weight: bold;
    transition-duration: 0.5s;
}

a:hover {
    text-decoration: underline;
}

table {
    border-collapse: collapse;
    border-spacing: 0;
    font-size: 1em;
    margin: 0 0 20px;
    width: 100%;
}

table tr:nth-child(2n),
thead {
    background-color: #f9f9f9;
}

tbody tr:hover {
    background: #f5f5f5
}

caption,
td,
th {
    font-weight: 400;
    padding: 8px;
    text-align: left;
    vertical-align: middle
}

table tr th {
    border-bottom: 3px solid #ddd;
    font-weight: 700;
    padding-bottom: 10px;
    background-color: var(--bg-color);
}

td,
th {
    border: 1px solid #ddd;
}

th {
    font-weight: 700;
    padding-bottom: 10px
}

td {
    border-bottom-width: 1px
}


/* Inline Code */

code,
.md-fences {
    background: #eee;
    border-radius: 3px;
    color: #555;
    padding: 2px 4px;
    overflow-wrap: break-word;
    word-wrap: break-word;
    font-family: 'JetBrains Mono';
    font-size: 0.935em;
}


/* Code Blocks */

.md-fences {
    margin: 0 0 20px;
    font-size: 0.9em;
    line-height: 1.5em;
    padding: 0.4em 1em;
    padding-top: 0.4em;
}

.task-list {
    padding-left: 0;
}

.task-list-item {
    padding-left: 2rem;
}

.task-list-item input {
    top: 3px;
}

.task-list-item input {
    outline: none;
    margin-bottom: 0.5em;
}

.task-list-item input::before {
    content: "";
    display: inline-block;
    width: 1rem;
    height: 1rem;
    vertical-align: middle;
    text-align: center;
    border: 1px solid gray;
    background-color: #fdfdfd;
    margin-left: -0.1rem;
    margin-right: 0.1rem;
    margin-top: -0.9rem;
}

.task-list-item input:checked::before {
    padding-left: 0.125em;
    content: '✔';
    /*◘*/
    font-size: 0.8125rem;
    line-height: 0.9375rem;
    margin-top: -0.9rem;
}


/* Chrome 29+ */

@media screen and (-webkit-min-device-pixel-ratio:0) and (min-resolution:.001dpcm) {
    .task-list-item input:before {
        margin-top: -0.2rem;
    }
    .task-list-item input:checked:before,
    .task-list-item input[checked]:before {
        margin-top: -0.2rem;
    }
}

blockquote {
    border-left: 4px solid #ddd;
    color: #666;
    margin: 0;
    margin-bottom: 10px;
    margin-top: 10px;
    padding: 0 15px
}

blockquote p {
    color: #666
}

blockquote cite::before {
    content: '-';
    padding: 0 5px
}


/* #write pre.md-meta-block {
    min-height: 30px;
    background: #f8f8f8;
    padding: 1.5em;
    font-weight: 300;
    font-size: 1em;
    padding-bottom: 1.5em;
    padding-top: 3em;
    margin-top: -1.5em;
    color: #999;
    border-left: 1000px #f8f8f8 solid;
    margin-left: -1000px;
    border-right: 1000px #f8f8f8 solid;
    margin-right: -1000px;
    margin-bottom: 2em;
    font-size: 0.8em;
    line-height: 1.5em;
    font-family: 'JetBrains Mono';
} */

#write pre.md-meta-block {
    padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f1f1f1;
    border: 0;
    border-radius: 3px;
    color: hsl(0, 0%, 53%);
    margin-top: 0 !important;
    margin-bottom: 2em;
    font-size: 0.8em;
    line-height: 1.5em;
    font-family: 'JetBrains Mono';
}

.MathJax_Display {
    font-size: 0.9em;
    margin-top: 0.5em;
    margin-bottom: 0;
}

p.mathjax-block,
.mathjax-block {
    padding-bottom: 0;
}

.mathjax-block>.code-tooltip {
    bottom: 5px;
    box-shadow: none;
}

.md-image>.md-meta {
    padding-left: 0.5em;
    padding-right: 0.5em;
}

.md-image>img {
    margin-top: 2px;
}

.md-image>.md-meta:first-of-type:before {
    padding-left: 4px;
}

#typora-source {
    color: #555;
}


/** ui for windows **/

#md-searchpanel {
    border-bottom: 1px solid #ccc;
}

#md-searchpanel .btn {
    border: 1px solid #ccc;
}

#md-notification:before {
    top: 14px;
}

#md-notification {
    background: #eee;
}

.megamenu-menu-panel .btn {
    border: 1px solid #ccc;
}

#write>h3.md-focus:before {
    left: -1.5625rem;
    top: .375rem;
}

#write>h4.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h5.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

#write>h6.md-focus:before {
    left: -1.5625rem;
    top: .285714286rem;
}

.md-image>.md-meta {
    border-radius: 3px;
    padding: 2px 0 0 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: inherit;
}

.md-toc {
    margin-top: 20px;
    padding-bottom: 5px;
}

.sidebar-tabs {
    border-bottom: none;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #efefef;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

#md-notification:before {
    top: 10px;
}


/** focus mode */

.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state {
    visibility: visible;
}

.md-lang {
    color: #b4654d;
}

.html-for-mac .context-menu {
    --item-hover-bg-color: #E6F0FE;
}

.file-tree-node {
    margin-top: 8px;
    margin-bottom: 8px;
}

.file-node-title {
    padding-top: 2px;
}

.outline-item {
    padding-top: 5px;
    padding-bottom: 5px;
    cursor: pointer;
}

/* 
.modal-footer .btn-default,
.modal-footer .btn-primary {
    border: 2px solid #222;
}



#md-searchpanel .btn:not(.close-btn):hover {
    background: #fff;
    border-color: #222;
    color: #222;
    -webkit-box-shadow: none;
    box-shadow: none;
}

#md-searchpanel .btn:not(.close-btn) {
    background: #222;
    border-color: #222;
    color: #fff;
    -webkit-box-shadow: none;
    box-shadow: none;
    transition-duration: .2s;
}

.searchpanel-search-option-btn {
    border-radius: 0px;
    border: 1px solid #222;
} */

/* Search panel & UI */

#md-searchpanel .btn {
    border: none;
}

#md-searchpanel input {
    box-shadow: none;
}

.searchpanel-search-option-btn {
    border-color: #aaa;
    border-radius: 0;
}

.modal-dialog .btn {
    background: #222;
    border-width: 2px;
    border-color: #222;
    border-radius: 0;
    color: #fff;
    display: inline-block;
    font-size: .875em;
    line-height: 2rem;
    padding: 0 20px;
    margin: 5px;
    text-decoration: none;
    transition-delay: 0s;
    transition-duration: .2s;
    transition-timing-function: ease-in-out
}

.modal-dialog .btn:hover {
    background: #eee;
    border-color: #222;
    color: #222;
}


/* Printing issue */

.typora-export * {
    -webkit-print-color-adjust: exact;
}

.typora-export p {
    font-size: var(--export-font-size) !important;
}

.typora-export li {
    font-size: var(--export-font-size);
    line-height: 2rem;
}

.typora-export #write {
    font-size: var(--export-font-size) !important;
}

table,
pre {
    page-break-inside: avoid;
}

pre {
    word-wrap: break-word;
}

hr {
    background-image: repeating-linear-gradient(-45deg, #ddd, #ddd 4px, transparent 4px, transparent 8px);
    border: 0;
    height: 3px;
    margin: 40px 0
}

 .typora-export li, .typora-export p, .typora-export,  .footnote-line {white-space: normal;} 
</style>
</head>
<body class='typora-export os-windows'>
<div id='write'  class=''><h1><a name="the-landscape-of-adversarial-example" class="md-header-anchor"></a><span>The Landscape of Adversarial Example</span></h1><p><span>By LI Haoyang 2020.10</span></p><h2><a name="content" class="md-header-anchor"></a><span>Content</span></h2><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n0"><a class="md-toc-inner" href="#the-landscape-of-adversarial-example">The Landscape of Adversarial Example</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n3"><a class="md-toc-inner" href="#content">Content</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n5"><a class="md-toc-inner" href="#problems">Problems</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n17"><a class="md-toc-inner" href="#map">Map</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n19"><a class="md-toc-inner" href="#attacks">Attacks</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n65"><a class="md-toc-inner" href="#defense">Defense</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n160"><a class="md-toc-inner" href="#explanation">Explanation</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n199"><a class="md-toc-inner" href="#interpretaion">Interpretaion</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n217"><a class="md-toc-inner" href="#benchmark">Benchmark</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n232"><a class="md-toc-inner" href="#false-positive-noise">False positive noise</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n237"><a class="md-toc-inner" href="#adversarial-augmentation">Adversarial augmentation</a></span></p></div><h2><a name="problems" class="md-header-anchor"></a><span>Problems</span></h2><p><span>Adversarial examples are such examples that 1) make no difference to human eyes 2) fool the targeted system to malfunction.  Many methods in deep learning have been discovered to be vulnerable to adversarial examples, along with many methods to generate adversarial examples. </span></p><p><span>For a target system </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.257ex" height="3.064ex" viewBox="0 -1001.7 1832.7 1319.3" role="img" focusable="false" style="vertical-align: -0.738ex;"><defs><path stroke-width="0" id="E5-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E5-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E5-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E5-MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path stroke-width="0" id="E5-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E5-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E5-MJMAIN-5E" x="276" y="227"></use><use xlink:href="#E5-MJMAIN-28" x="776" y="0"></use><use xlink:href="#E5-MJMAIN-22C5" x="1165" y="0"></use><use xlink:href="#E5-MJMAIN-29" x="1443" y="0"></use></g></svg></span><script type="math/tex">\hat{F}(\cdot)</script><span> estimated from original map </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.192ex" height="2.698ex" viewBox="0 -843.8 1805 1161.5" role="img" focusable="false" style="vertical-align: -0.738ex;"><defs><path stroke-width="0" id="E6-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E6-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E6-MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path stroke-width="0" id="E6-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E6-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E6-MJMAIN-28" x="749" y="0"></use><use xlink:href="#E6-MJMAIN-22C5" x="1138" y="0"></use><use xlink:href="#E6-MJMAIN-29" x="1416" y="0"></use></g></svg></span><script type="math/tex">F(\cdot)</script><span> and a target input </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.476ex" viewBox="0 -528.1 572 635.4" role="img" focusable="false" style="vertical-align: -0.249ex;"><defs><path stroke-width="0" id="E7-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E7-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script><span>, the goal is to generate an adversarial example </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.641ex" height="2.209ex" viewBox="0 -791.2 4151 951" role="img" focusable="false" style="vertical-align: -0.371ex;"><defs><path stroke-width="0" id="E8-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E8-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E8-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E8-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E8-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E8-MJMATHI-78" x="0" y="0"></use><use xlink:href="#E8-MJMAIN-5E" x="63" y="-11"></use><use xlink:href="#E8-MJMAIN-3D" x="849" y="0"></use><use xlink:href="#E8-MJMATHI-78" x="1905" y="0"></use><use xlink:href="#E8-MJMAIN-2B" x="2699" y="0"></use><use xlink:href="#E8-MJMATHI-3B4" x="3700" y="0"></use></g></svg></span><script type="math/tex">\hat{x}=x+\delta</script><span> with a minimal perturbation </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.047ex" height="2.087ex" viewBox="0 -791.2 451 898.4" role="img" focusable="false" style="vertical-align: -0.249ex;"><defs><path stroke-width="0" id="E9-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E9-MJMATHI-3B4" x="0" y="0"></use></g></svg></span><script type="math/tex">\delta</script><span> , such that </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.976ex" height="3.064ex" viewBox="0 -1001.7 5587 1319.3" role="img" focusable="false" style="vertical-align: -0.738ex;"><defs><path stroke-width="0" id="E10-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E10-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E10-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E10-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E10-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E10-MJMAIN-2260" d="M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E10-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E10-MJMAIN-5E" x="276" y="227"></use><use xlink:href="#E10-MJMAIN-28" x="776" y="0"></use><g transform="translate(1165,0)"><use xlink:href="#E10-MJMATHI-78" x="0" y="0"></use><use xlink:href="#E10-MJMAIN-5E" x="63" y="-11"></use></g><use xlink:href="#E10-MJMAIN-29" x="1737" y="0"></use><use xlink:href="#E10-MJMAIN-2260" x="2404" y="0"></use><g transform="translate(3460,0)"><use xlink:href="#E10-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E10-MJMAIN-5E" x="276" y="227"></use></g><use xlink:href="#E10-MJMAIN-28" x="4237" y="0"></use><use xlink:href="#E10-MJMATHI-78" x="4626" y="0"></use><use xlink:href="#E10-MJMAIN-29" x="5198" y="0"></use></g></svg></span><script type="math/tex">\hat{F}(\hat{x})\neq \hat{F}(x)</script><span>:</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n8" cid="n8" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="104.236ex" height="8.074ex" viewBox="0 -843.8 44879.3 3476.5" role="img" focusable="false" style="vertical-align: -6.115ex; max-width: 100%;"><defs><path stroke-width="0" id="E2-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path><path stroke-width="0" id="E2-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E2-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E2-MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path stroke-width="0" id="E2-MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E2-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E2-MJMAIN-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path stroke-width="0" id="E2-MJMATHI-3B5" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path><path stroke-width="0" id="E2-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E2-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path stroke-width="0" id="E2-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="0" id="E2-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E2-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E2-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E2-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E2-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E2-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E2-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E2-MJMAIN-2260" d="M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(19551,0)"><use xlink:href="#E2-MJMATHI-3B4" x="0" y="0"></use><use xlink:href="#E2-MJMAIN-3D" x="728" y="0"></use><g transform="translate(1784,0)"><g transform="translate(158,0)"><use xlink:href="#E2-MJMAIN-6D"></use><use xlink:href="#E2-MJMAIN-69" x="833" y="0"></use><use xlink:href="#E2-MJMAIN-6E" x="1111" y="0"></use></g><g transform="translate(0,-697)"><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-7C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-7C" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMATHI-3B4" x="556" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-7C" x="1007" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-7C" x="1285" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-3C" x="1563" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMATHI-3B5" x="2341" y="0"></use></g></g><use xlink:href="#E2-MJMAIN-7C" x="3936" y="0"></use><use xlink:href="#E2-MJMAIN-7C" x="4214" y="0"></use><use xlink:href="#E2-MJMATHI-3B4" x="4492" y="0"></use><use xlink:href="#E2-MJMAIN-7C" x="4943" y="0"></use><use xlink:href="#E2-MJMAIN-7C" x="5221" y="0"></use><use xlink:href="#E2-MJMAIN-2C" x="5499" y="0"></use></g><g transform="translate(17949,-2326)"><use xlink:href="#E2-MJMATHI-73" x="0" y="0"></use><use xlink:href="#E2-MJMAIN-2E" x="469" y="0"></use><use xlink:href="#E2-MJMATHI-74" x="913" y="0"></use><use xlink:href="#E2-MJMAIN-2E" x="1274" y="0"></use><g transform="translate(1719,0)"><use xlink:href="#E2-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E2-MJMAIN-5E" x="276" y="227"></use></g><use xlink:href="#E2-MJMAIN-28" x="2496" y="0"></use><use xlink:href="#E2-MJMATHI-78" x="2885" y="0"></use><use xlink:href="#E2-MJMAIN-2B" x="3679" y="0"></use><use xlink:href="#E2-MJMATHI-3B4" x="4679" y="0"></use><use xlink:href="#E2-MJMAIN-29" x="5130" y="0"></use><use xlink:href="#E2-MJMAIN-2260" x="5797" y="0"></use><g transform="translate(6853,0)"><use xlink:href="#E2-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E2-MJMAIN-5E" x="276" y="227"></use></g><use xlink:href="#E2-MJMAIN-28" x="7629" y="0"></use><use xlink:href="#E2-MJMATHI-78" x="8018" y="0"></use><use xlink:href="#E2-MJMAIN-29" x="8590" y="0"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">\delta=\mathop{\min}\limits_{||\delta||<\varepsilon} ||\delta||,\\
s.t. \hat{F}(x+\delta)\neq \hat{F}(x)</script></div></div><p><span>By the attacker&#39;s knowledge of the system, these methods are divided into white-box and black-box, the former assumes the attacker have full knowledge of the system while the latter does not make such assumptions, which makes the former easier and popular in literature, less meaningful in practice and the latter more difficult and weirder in literature, more meaningful in practice. Between black and white, some also call the scenario when attacker has limited knowledge as gray-box.</span></p><p><mark><span>The problem of generating adversarial examples is a reversed optimization problem, in which the parameters of the targeted model is fixed, while the input is tuned to mislead the model under certain constraints.</span></mark><span> The white-box methods generally utilize the gradients of the model, and the black-box methods either utilize the transferability of adversarial examples, or solve the problem with zero-order optimization algorithms (e.g. evolutionary algorithms, reinforcement learning, etc. ).</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n11" cid="n11" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="104.236ex" height="8.074ex" viewBox="0 -1001.7 44879.3 3476.5" role="img" focusable="false" style="vertical-align: -5.748ex; max-width: 100%;"><defs><path stroke-width="0" id="E21-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path><path stroke-width="0" id="E21-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E21-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="0" id="E21-MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path stroke-width="0" id="E21-MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path><path stroke-width="0" id="E21-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E21-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="0" id="E21-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E21-MJMAIN-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path stroke-width="0" id="E21-MJMATHI-3B5" d="M190 -22Q124 -22 76 11T27 107Q27 174 97 232L107 239L99 248Q76 273 76 304Q76 364 144 408T290 452H302Q360 452 405 421Q428 405 428 392Q428 381 417 369T391 356Q382 356 371 365T338 383T283 392Q217 392 167 368T116 308Q116 289 133 272Q142 263 145 262T157 264Q188 278 238 278H243Q308 278 308 247Q308 206 223 206Q177 206 142 219L132 212Q68 169 68 112Q68 39 201 39Q253 39 286 49T328 72T345 94T362 105Q376 103 376 88Q376 79 365 62T334 26T275 -8T190 -22Z"></path><path stroke-width="0" id="E21-MJCAL-4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path><path stroke-width="0" id="E21-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E21-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E21-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E21-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E21-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E21-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E21-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(15709,0)"><use xlink:href="#E21-MJMATHI-3B4" x="0" y="0"></use><use xlink:href="#E21-MJMAIN-3D" x="728" y="0"></use><g transform="translate(1784,0)"><use xlink:href="#E21-MJMAIN-61"></use><use xlink:href="#E21-MJMAIN-72" x="500" y="0"></use><use xlink:href="#E21-MJMAIN-67" x="892" y="0"></use><g transform="translate(1558,0)"><use xlink:href="#E21-MJMAIN-6D"></use><use xlink:href="#E21-MJMAIN-61" x="833" y="0"></use><use xlink:href="#E21-MJMAIN-78" x="1333" y="0"></use></g><g transform="translate(717,-903)"><use transform="scale(0.707)" xlink:href="#E21-MJMAIN-7C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMAIN-7C" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMATHI-3B4" x="556" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMAIN-7C" x="1007" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMAIN-7C" x="1285" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMAIN-3C" x="1563" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMATHI-3B5" x="2341" y="0"></use></g></g><use xlink:href="#E21-MJCAL-4C" x="5370" y="0"></use><use xlink:href="#E21-MJMAIN-28" x="6060" y="0"></use><g transform="translate(6449,0)"><use xlink:href="#E21-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E21-MJMAIN-5E" x="276" y="227"></use></g><use xlink:href="#E21-MJMAIN-28" x="7226" y="0"></use><use xlink:href="#E21-MJMATHI-78" x="7615" y="0"></use><use xlink:href="#E21-MJMAIN-2B" x="8409" y="0"></use><use xlink:href="#E21-MJMATHI-3B4" x="9410" y="0"></use><use xlink:href="#E21-MJMAIN-29" x="9861" y="0"></use><use xlink:href="#E21-MJMAIN-2C" x="10250" y="0"></use><use xlink:href="#E21-MJMATHI-46" x="10694" y="0"></use><use xlink:href="#E21-MJMAIN-28" x="11443" y="0"></use><use xlink:href="#E21-MJMATHI-78" x="11832" y="0"></use><use xlink:href="#E21-MJMAIN-29" x="12404" y="0"></use><use xlink:href="#E21-MJMAIN-29" x="12793" y="0"></use><use xlink:href="#E21-MJMAIN-2C" x="13182" y="0"></use></g><g transform="translate(20364,-2327)"><use xlink:href="#E21-MJMATHI-78" x="0" y="0"></use><use xlink:href="#E21-MJMAIN-5E" x="63" y="-11"></use><use xlink:href="#E21-MJMAIN-3D" x="849" y="0"></use><use xlink:href="#E21-MJMATHI-78" x="1905" y="0"></use><use xlink:href="#E21-MJMAIN-2B" x="2699" y="0"></use><use xlink:href="#E21-MJMATHI-3B4" x="3700" y="0"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">\delta=\mathop{\arg\max}\limits_{||\delta||<\varepsilon}\mathcal{L}(\hat{F}(x+\delta),F(x)),\\
\hat{x}=x+\delta</script></div></div><p><span>Most white-box attack (i.e. the most prevailing methods) reforms the problem into a reversed training where the loss is maximized rather than minimized. </span></p><p><span>The defense of adversarial attack is more difficult and no method has defended all adversarial attacks. Theoretically, a min-max optimization is formulated with the idea of adversarial training to train a robust model.</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n14" cid="n14" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="39.889ex" height="5.997ex" viewBox="0 -1527.8 17174.4 2582.1" role="img" focusable="false" style="vertical-align: -2.449ex; max-width: 100%;"><defs><path stroke-width="0" id="E22-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E22-MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path stroke-width="0" id="E22-MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E22-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path><path stroke-width="0" id="E22-MJAMS-45" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path><path stroke-width="0" id="E22-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E22-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E22-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E22-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E22-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E22-MJMAIN-223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path><path stroke-width="0" id="E22-MJCAL-44" d="M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z"></path><path stroke-width="0" id="E22-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="0" id="E22-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="0" id="E22-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="0" id="E22-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path><path stroke-width="0" id="E22-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path stroke-width="0" id="E22-MJCAL-53" d="M554 512Q536 512 536 522Q536 525 539 539T542 564Q542 588 528 604Q515 616 482 625T410 635Q374 635 349 624T312 594T295 561T290 532Q290 505 303 482T342 442T378 419T409 404Q435 391 451 383T494 357T535 323T562 282T574 231Q574 133 464 56T220 -22Q138 -22 78 21T18 123Q18 184 61 227T156 274Q178 274 178 263Q178 260 177 258Q172 247 164 239T151 227T136 218L127 213L124 202Q118 186 118 163Q120 124 165 86T292 48Q374 48 423 86T473 186V193Q473 267 347 327Q268 364 239 389Q191 431 191 486Q191 547 242 600T356 679T470 705Q472 705 478 705T489 704Q551 704 596 682T642 610Q642 566 621 545Q592 516 554 512Z"></path><path stroke-width="0" id="E22-MJCAL-4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path><path stroke-width="0" id="E22-MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="0" id="E22-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="0" id="E22-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E22-MJMAIN-3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path><path stroke-width="0" id="E22-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="0" id="E22-MJSZ3-5B" d="M247 -949V1450H516V1388H309V-887H516V-949H247Z"></path><path stroke-width="0" id="E22-MJSZ3-5D" d="M11 1388V1450H280V-949H11V-887H218V1388H11Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E22-MJMAIN-6D"></use><use xlink:href="#E22-MJMAIN-69" x="833" y="0"></use><use xlink:href="#E22-MJMAIN-6E" x="1111" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMATHI-3B8" x="944" y="-941"></use><g transform="translate(1833,0)"><use xlink:href="#E22-MJAMS-45" x="0" y="0"></use><g transform="translate(667,-186)"><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-28" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMATHI-78" x="389" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-2C" x="961" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMATHI-79" x="1239" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-29" x="1735" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-223C" x="2125" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJCAL-44" x="2903" y="0"></use></g></g><g transform="translate(5365,0)"><use xlink:href="#E22-MJSZ3-5B"></use><g transform="translate(528,0)"><use xlink:href="#E22-MJMAIN-6D"></use><use xlink:href="#E22-MJMAIN-61" x="833" y="0"></use><use xlink:href="#E22-MJMAIN-78" x="1333" y="0"></use><g transform="translate(308,-685)"><use transform="scale(0.707)" xlink:href="#E22-MJMATHI-3B4" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-2208" x="451" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJCAL-53" x="1118" y="0"></use></g></g><use xlink:href="#E22-MJCAL-4C" x="2555" y="0"></use><use xlink:href="#E22-MJMAIN-28" x="3245" y="0"></use><g transform="translate(3634,0)"><use xlink:href="#E22-MJMATHI-46" x="0" y="0"></use><use xlink:href="#E22-MJMAIN-5E" x="276" y="227"></use></g><use xlink:href="#E22-MJMAIN-28" x="4411" y="0"></use><use xlink:href="#E22-MJMATHI-78" x="4800" y="0"></use><use xlink:href="#E22-MJMAIN-2B" x="5594" y="0"></use><use xlink:href="#E22-MJMATHI-3B4" x="6594" y="0"></use><use xlink:href="#E22-MJMAIN-3B" x="7045" y="0"></use><use xlink:href="#E22-MJMATHI-3B8" x="7490" y="0"></use><use xlink:href="#E22-MJMAIN-29" x="7959" y="0"></use><use xlink:href="#E22-MJMAIN-2C" x="8348" y="0"></use><use xlink:href="#E22-MJMATHI-46" x="8793" y="0"></use><use xlink:href="#E22-MJMAIN-28" x="9542" y="0"></use><use xlink:href="#E22-MJMATHI-78" x="9931" y="0"></use><use xlink:href="#E22-MJMAIN-29" x="10503" y="0"></use><use xlink:href="#E22-MJMAIN-29" x="10892" y="0"></use><use xlink:href="#E22-MJSZ3-5D" x="11281" y="-1"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-3">\min_{\theta}
\Bbb{E}_{(x,y)\sim \cal{D}}
\left[\max_{\delta\in\cal{S}}\mathcal{L}(\hat{F}(x+\delta;\theta),F(x))\right]</script></div></div><p><span>The inner formulation searches an optimal perturbation in allowed perturbations </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.491ex" height="2.087ex" viewBox="0 -791.2 642 898.4" role="img" focusable="false" style="vertical-align: -0.249ex;"><defs><path stroke-width="0" id="E11-MJCAL-53" d="M554 512Q536 512 536 522Q536 525 539 539T542 564Q542 588 528 604Q515 616 482 625T410 635Q374 635 349 624T312 594T295 561T290 532Q290 505 303 482T342 442T378 419T409 404Q435 391 451 383T494 357T535 323T562 282T574 231Q574 133 464 56T220 -22Q138 -22 78 21T18 123Q18 184 61 227T156 274Q178 274 178 263Q178 260 177 258Q172 247 164 239T151 227T136 218L127 213L124 202Q118 186 118 163Q120 124 165 86T292 48Q374 48 423 86T473 186V193Q473 267 347 327Q268 364 239 389Q191 431 191 486Q191 547 242 600T356 679T470 705Q472 705 478 705T489 704Q551 704 596 682T642 610Q642 566 621 545Q592 516 554 512Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E11-MJCAL-53" x="0" y="0"></use></g></svg></span><script type="math/tex">\cal{S}</script><span> and the outer formulation searches an optimal parameter </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.089ex" height="2.087ex" viewBox="0 -791.2 469 898.4" role="img" focusable="false" style="vertical-align: -0.249ex;"><defs><path stroke-width="0" id="E12-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E12-MJMATHI-3B8" x="0" y="0"></use></g></svg></span><script type="math/tex">\theta</script><span> to minimize the loss function respect to the perturbed example. </span></p><p><span>Based on the same minimax problem, while adversarial training aims to find a lower bound for the inner maximization, efforts in provable defense attempt to find an upper bound for the inner maximization. The latter is also known as verification of robustness. </span></p><h2><a name="map" class="md-header-anchor"></a><span>Map</span></h2><p><a href="Map-AdversarialExample.html" target="_blank"><span>A Map of Adversarial Example Research</span></a></p><h2><a name="attacks" class="md-header-anchor"></a><span>Attacks</span></h2><p><a href="Note-AdversarialAttack.html" target="_blank"><span>Adversarial Attacks</span></a></p><ul><li><p><em><span>Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus. Intriguing properties of neural networks. ICLR 2014.</span></em><span> </span><strong><em><a href='https://arxiv.org/abs/1312.6199'><span> arXiv:1312.6199</span></a></em></strong><span> </span></p><p><mark><span>This is the initial commit of adversarial example, they assume that it&#39;s caused by the exploded gradient along minor perturbations.</span></mark></p></li><li><p><em><span>Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. ICLR 2015.</span></em><span> (</span><strong><span>AT with FGSM</span></strong><span>)</span></p><p><mark><span>They propose to defend adversarial attack using adversarial training, i.e. use the online generated adversarial example to augment the training data, and for this purpose, they also propose Fast Gradient Sign Method as a fast attack, utilizing the local linearity.</span></mark></p></li><li><p><em><span>Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard. DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks. CVPR 2016.</span></em><span> </span><strong><em><a href='https://arxiv.org/abs/1511.04599'><span> arXiv:1511.04599</span></a></em></strong><span> (</span><strong><span>DeepFool</span></strong><span>)</span></p><p><mark><span>They give a comprehensive analysis of adversarial example from a geometry perspective, and propose to use the perturbation orthogonal with the nearest classification boundary as adversarial perturbation, i.e. the DeepFool attack.</span></mark></p></li><li><p><em><span>Nicholas Carlini, David Wagner. Towards Evaluating the Robustness of Neural Networks. SSP 2017. </span><strong><a href='https://arxiv.org/abs/1608.04644'><span> arXiv:1608.04644</span></a></strong></em><span> (</span><strong><span>Carlini&amp;Wagner Attack</span></strong><span>)</span></p><p><mark><span>They give a comprehensive investigation of white-box gradient-based adversarial attacks, experiment different loss functions and propose one empirically optimal attack for </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.746ex" height="2.331ex" viewBox="0 -791.2 751.6 1003.7" role="img" focusable="false" style="vertical-align: -0.493ex;"><defs><path stroke-width="0" id="E13-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E13-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E13-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E13-MJMAIN-31" x="421" y="-213"></use></g></svg></span><script type="math/tex">l_1</script><span>, </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.746ex" height="2.331ex" viewBox="0 -791.2 751.6 1003.7" role="img" focusable="false" style="vertical-align: -0.493ex;"><defs><path stroke-width="0" id="E16-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E16-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E16-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E16-MJMAIN-32" x="421" y="-213"></use></g></svg></span><script type="math/tex">l_2</script><span> and </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.567ex" height="2.331ex" viewBox="0 -791.2 1105.1 1003.7" role="img" focusable="false" style="vertical-align: -0.493ex;"><defs><path stroke-width="0" id="E15-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E15-MJMAIN-221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E15-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMAIN-221E" x="421" y="-213"></use></g></svg></span><script type="math/tex">l_{\infty}</script><span> norm, i.e. the Carlini&amp;Wagner attack.</span></mark></p></li><li><p><em><span>Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard. Universal adversarial perturbations. CVPR 2017. </span><strong><a href='https://arxiv.org/abs/1610.08401'><span> arXiv:1610.08401</span></a></strong></em><span> (</span><strong><span>UAP</span></strong><span>)</span></p><p><mark><span>They investigate a special type of adversarial perturbation, i.e. universal adversarial perturbations, which can fool the classifier class agnosticly. They also explain that the existence of universal adversarial perturbations is caused by the geometric correlation of classification boundaries.</span></mark></p></li><li><p><em><span>Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z. Berkay Celik, Ananthram Swami. Practical Black-Box Attacks against Machine Learning. CCS 2017. </span><strong><a href='https://arxiv.org/abs/1602.02697'><span> arXiv:1602.02697</span></a></strong></em><span> (</span><strong><span>Substitute Attack</span></strong><span>)</span></p><p><mark><span>They propose to train a substitute model to approximate the decision boundary of the black-box model. Start with a few representative examples, label them by querying the black-box model, augment them with adversarial examples generated using white-box attack againt the substitute model and do it iteratively.</span></mark></p></li><li><p><em><span>Alexey Kurakin, Ian Goodfellow, Samy Bengio. Adversarial example in the physical world. ICLR 2017. </span><strong><a href='https://arxiv.org/abs/1607.02533'><span> arXiv:1607.02533</span></a></strong></em></p><p><mark><span>They first prove the existence of physical adversarial example,e.g. a printed adversarial example recaptured by camera can still fool the classifier.</span></mark></p></li></ul><p><a href="Note-AdversarialExampleOD.html" target="_blank"><span>Adversarial Example in Object Detection</span></a></p><ul><li><p><em><span>Mahmood Sharif, Scruti Bhagavatula, Lujo Bauer, Michael Reiter. Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition. 1528-1540. 10.1145/2976749.2978392.</span></em><span>  </span><em><span>SIGSAC 2016</span></em><span> </span><strong><em><span>Paper: </span><a href='https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf' target='_blank' class='url'>https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf</a></em></strong><span> (</span><strong><span>Adversarial Glasses</span></strong><span>)</span></p><p><mark><span>They craft an adversarial glass that can fool face recognition system.</span></mark></p></li><li><p><em><span>Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, Alan Yuille. Adversarial Examples for Semantic Segmentation and Object Detection. ICCV 2017. </span><strong><a href='https://ui.adsabs.harvard.edu/link_gateway/2017arXiv170308603X/arXiv:1703.08603'><span>arXiv:1703.08603</span></a></strong></em></p><p><mark><span>They craft adversarial examples for object detection and semantic segmentation, specially, they can design the prediction of semantic segmentation.</span></mark></p></li><li><p><em><span>Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi Kohno, Dawn Song. Robust Physical-World Attacks on Deep Learning Models. CVPR 2018 </span><strong><a href='https://arxiv.org/abs/1707.08945'><span> arXiv:1707.08945</span></a></strong></em></p><p><mark><span>They craft robust physical adversarial perturbations on traffic signs.</span></mark></p></li><li><p><em><span>Simen Thys, Wiebe Van Ranst, Toon Goedemé. Fooling automated surveillance cameras: adversarial patches to attack person detection. CVPR workshop 2019 </span><a href='https://arxiv.org/abs/1904.08653'><span> </span><strong><span>arXiv:1904.08653</span></strong></a></em><span>  (</span><strong><span>Adversarial Patch</span></strong><span>)</span></p><p><mark><span>They craft an adversarial patch, with which carried in front, one can avoid the object detection of YOLO.</span></mark></p></li><li><p><em><span>Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, Xue Lin. Adversarial T-shirt! Evading Person Detectors in A Physical World. ECCV 2020. </span><strong><a href='https://arxiv.org/abs/1910.11099'><span> arXiv:1910.11099</span></a></strong></em><span> (</span><strong><span>Adversarial T-shirt</span></strong><span>)</span></p><p><mark><span>They craft an adversarial T-shirt, wearing which one can become &quot;invisible&quot; in the eyes of YOLO.</span></mark></p></li><li><p><em><span>Zuxuan Wu, Ser-Nam Lim, Larry Davis, Tom Goldstein. Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors. ECCV 2020. </span><strong><a href='https://arxiv.org/abs/1910.14667'><span> arXiv:1910.14667</span></a></strong></em></p></li><li><p><em><span>Haichao Zhang, Jianyu Wang. Towards Adversarially Robust Object Detection. ICCV 2019.</span></em><span> </span><strong><em><span>Paper: </span><a href='https://openaccess.thecvf.com/content_ICCV_2019/html/Zhang_Towards_Adversarially_Robust_Object_Detection_ICCV_2019_paper.html'><span>ICCV 2019- Towards Adversarially Robust Object Detection</span></a></em></strong></p><p><mark><span>They propose adversarial training for robust detection, choosing the stronger adversarial example crafted either for classification task or for localization task at each batch.</span></mark></p></li></ul><h2><a name="defense" class="md-header-anchor"></a><span>Defense</span></h2><p><a href="Note-AdversarialDefense.html" target="_blank"><span>Defenses against Adversarial Attacks</span></a></p><p><span>Regularization</span></p><ul><li><p><em><span>Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, Nicolas Usunier. Parseval Networks: Improving Robustness to Adversarial Examples. ICML 2017. </span><strong><a href='https://arxiv.org/abs/1704.08847'><span> arXiv:1704.08847</span></a></strong></em></p><p><mark><span>They propose to regularize the power of the weights of network by making the weights orthogonal to itself (this kind of weight is also known as a Parseval tight frame) as a defense.</span></mark></p></li><li><p><em><span>Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli. Adversarial robustness through local linearization. NIPS 2019. </span><strong><a href='https://arxiv.org/abs/1907.02610'><span> arXiv:1907.02610</span></a></strong></em><span> (</span><strong><span>LLR</span></strong><span>)</span></p><p><mark><span>They propose to penalize the loss with a local linearization term, i.e. enforcing the loss function to be well approximated by its first-order taylor expansion. Besides the local linearization term, they also add a magnitude term to restrict the magnitude of the gradients of loss.</span></mark></p></li><li><p><em><span>Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu. Jacobian Adversarially Regularized Networks for Robustness. ICLR 2020. </span><a href='https://arxiv.org/abs/1912.10185'><span> </span><strong><span>arXiv:1912.10185</span></strong></a></em><span> (</span><strong><span>JARN</span></strong><span>)</span></p><p><mark><span>They use a GAN to enforce the Jacobian of objective to be similar to the inputs, as empirically observed that adversarially trained networks have a gradient more similar to the input image.</span></mark></p></li></ul><p><span>Adversarial Training</span></p><ul><li><p><em><span>Harini Kannan, Alexey Kurakin, Ian Goodfellow. Adversarial Logit Pairing. arXiv preprint 2018 </span><strong><a href='https://arxiv.org/abs/1803.06373'><span> arXiv:1803.06373</span></a></strong></em><span> (</span><strong><span>ALP</span></strong><span>)</span></p><p><mark><span>They propose to enforce the logits activated by a clean image and its adversarial counterpart to be similar by adding a penalizing term in the objective. It&#39;s in fact a type of adversarial training on logits.</span></mark></p></li><li><p><em><span>Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu. Towards Deep Learning Models Resistant to Adversarial Attacks. ICLR 2018. </span><strong><a href='https://arxiv.org/abs/1706.06083'><span> arXiv:1706.06083</span></a></strong></em><span> (</span><strong><span>AT with PGD</span></strong><span>)</span></p><p><mark><span>They claim that Project Gradient Descent attack is the ultimate white-box attack and propose to use PGD attack in adversarial training, besides, they also prove that when the inner maximizer is reached, an update on the outer minimizer can find the optimal for the minimax problem of adversarial training.</span></mark></p></li><li><p><em><span>Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S. Davis, Gavin Taylor, Tom Goldstein. Adversarial Training for Free! NIPS 2019. </span><a href='https://arxiv.org/abs/1904.12843v2'><strong><span>arXiv:1904.12843v2</span></strong></a></em><span> (</span><strong><span>AT for free</span></strong><span>)</span></p><p><mark><span>Thye modify the adversarial training in order to accelerate it. Instead of launching K steps of PGD to generate a batch of adversarial examples and then train the model with them for one time, they launches 1 steps of PGD for the same batch and train model for m times.</span></mark></p></li><li><p><em><span>Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong. You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle. NIPS 2019.</span></em><span> </span><strong><em><span>Paper: </span><a href='http://papers.nips.cc/paper/8316-you-only-propagate-once-accelerating-adversarial-training-via-maximal-principle' target='_blank' class='url'>http://papers.nips.cc/paper/8316-you-only-propagate-once-accelerating-adversarial-training-via-maximal-principle</a></em></strong><span> (</span><strong><span>YOPO</span></strong><span>)</span></p><p><mark><span>They utilize the Pontryagin Maximization Principle to accelerate the original adversarial training.</span></mark></p></li><li><p><em><span>Jonathan Uesato, Jean-Baptiste Alayrac, Po-Sen Huang, Robert Stanforth, Alhussein Fawzi, Pushmeet Kohli. Are Labels Required for Improving Adversarial Robustness?. NIPS 2019. </span><a href='https://arxiv.org/abs/1905.13725'><span> </span><strong><span>arXiv:1905.13725</span></strong></a></em><span> (</span><strong><span>UAT</span></strong><span>)</span></p><p><mark><span>They propose to use the unlabeled data along with labeled to augment adversarial training. For the unlabeled data, they use either the label predicted by the model online or the logits generated by the model. This is discovered by decomposing the loss objective used by adversarial training.</span></mark></p></li><li><p><em><span>Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli. Attacks Which Do Not Kill Training Make Adversarial Learning Stronger. ICML 2020. </span><a href='https://arxiv.org/abs/2002.11242'><strong><span>arXiv:2002.11242</span></strong></a></em><span> (</span><strong><span>FAT</span></strong><span>)</span></p><p><mark><span>They point out that a very strong adversary can flip the distribution of data, making the label uncorrelated completely, thus hindering the performance of adversarial training. So they propose the idea of friendly adversarial training and implement it by early stopping the adversarial attack.</span></mark></p></li><li><p><em><span>Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, Michael I. Jordan. Theoretically Principled Trade-off between Robustness and Accuracy. ICML 2019. </span><strong><a href='https://arxiv.org/abs/1901.08573'><span> arXiv:1901.08573</span></a></strong></em><span> (</span><strong><span>TRADES</span></strong><span>)</span></p><p><mark><span>They analyze the trade-off between robustness and accuracy, then propose to add a regularization term for robustness in the objective. The regularization term enforces the logits of adversarial example and corresponding clean examples to be similar, just like the Adversarial Logit Pairing.</span></mark></p></li><li><p><em><span>Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan Yuille, Kaiming He. Feature Denoising for Improving Adversarial Robustness. CVPR 2019.  </span><a href='https://arxiv.org/abs/1812.03411'><span> </span><strong><span>arXiv:1812.03411</span></strong></a></em><span> (</span><strong><span>Feature Denoising</span></strong><span>)</span></p><p><mark><span>They observe that the feature map activated by adversarial examples appears to be much more noisier than clean examples, hence proposing a feature denoising block (the structure is similar to a residual block). It should be used along with adversarial training.</span></mark></p></li><li><p><em><span>Eric Wong, Leslie Rice, J. Zico Kolter. Fast is better than free: Revisiting adversarial training. ICLR 2020</span></em><span>. </span><strong><em><span>Paper: </span><a href='https://openreview.net/forum?id=BJx040EFvH&amp;noteId=BJx040EFvH' target='_blank' class='url'>https://openreview.net/forum?id=BJx040EFvH&noteId=BJx040EFvH</a></em></strong><span> (</span><strong><span>AT with FGSM RS</span></strong><span>)</span></p><p><mark><span>They revisit the adversarial training with FGSM and find that using a large step induces a phenomenon they named as catastrophic overfitting. They propose to use FGSM with random start to mitigate this phenomenon. FGSM with random start has been proposed before, but used for ensemble adversarial training.</span></mark></p></li><li><p><em><span>Maksym Andriushchenko, Nicolas Flammarion. Understanding and Improving Fast Adversarial Training. NIPS 2020.</span></em><span> </span><strong><em><span>Paper: </span><a href='https://infoscience.epfl.ch/record/278914' target='_blank' class='url'>https://infoscience.epfl.ch/record/278914</a></em></strong><span> (</span><strong><span>AT with FGSM GradAlign</span></strong><span>)</span></p><p><mark><span>They carefully revisit the adversarial training with FGSM RS and point it out that it in fact reduces the equivalent step size and still suffers from catastrophic overfitting. Besides, they discover that adversarial training for free and adversarial training with two steps of PGD also suffers from catastrophic overfitting.</span></mark></p><p><mark><span>They further discover that when the catastrophic overfitting appears, the gradient alignment, i.e. the cosine similarity between the gradient of loss respect to clean example and adversarial counterpart, starts to drop simultaneously, making FGSM ineffective. They propose to use a gradient alignment term in objective to align the gradients such that adversarial training with FGSM works again.</span></mark></p></li><li><p><em><span>Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, Quoc V. Le. Smooth Adversarial Training. arXiv preprint 2020 </span><strong><a href='https://arxiv.org/abs/2006.14536'><span>arXiv:2006.14536</span></a></strong></em></p><p><mark><span>They propose to use a smooth activation function for a better backpropagation only in PGD attacks in adversarial training.</span></mark></p></li><li><p><em><span>Amirreza Shaeiri, Rozhin Nobahari, Mohammad Hossein Rohban. Towards Deep Learning Models Resistant to Large Perturbations. arXiv preprint 2020. </span><a href='https://arxiv.org/abs/2003.13370'><span> </span><strong><span>arXiv:2003.13370</span></strong></a></em><span> (</span><strong><span>Iterative AT</span></strong><span>)</span></p><p><mark><span>They discover that adversarial training with PGD fails when directly started with a large step size and propose to initialize the network with the adversarially trained weights using a smaller step size before training with a large step size. Based on this idea, they also propose an iterative adversarial training that increases the step size gradually as the training progresses.</span></mark></p></li></ul><p><span>Provable Defenses/Verification</span></p><ul><li><p><em><span>Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, Pengchuan Zhang. A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks. NIPS 2019. </span><strong><a href='https://arxiv.org/abs/1902.08722'><span> arXiv:1902.08722</span></a></strong></em></p><p><mark><span>They connect all the existing convex relaxation of robustness verification and point out that there is a convex barrier (a difference cuased by convex relaxation) hindering these relaxation from properly verify the robustness.</span></mark></p></li><li><p><em><span>Jeet Mohapatra, Tsui-Wei (Lily)Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel. Towards Verifying Robustness of Neural Networks Against A Family of Semantic Perturbations. CVPR 2020. </span><strong><a href='https://arxiv.org/abs/1912.09533'><span> arXiv:1912.09533</span></a></strong></em><span> (</span><strong><span>Sematify-NN</span></strong><span>)</span></p><p><mark><span>They incorparate multiple simantic perturbations into layers of neural networks, and propose to use this network to verify the robustness of model against semantic perturbations.</span></mark></p></li><li><p><em><span>Mislav Balunovic, Martin Vechev. Adversarial Training and Provable Defenses: Bridging the Gap. ICLR 2020.</span></em><span>  </span><strong><em><span>Paper: </span><a href='https://openreview.net/forum?id=SJxSDxrKDr' target='_blank' class='url'>https://openreview.net/forum?id=SJxSDxrKDr</a></em></strong><span> (</span><strong><span>COLT</span></strong><span>)</span></p><p><mark><span>The propose a Convex Layerwise Adversarial Training incorparating verification and adversarial training. It can be seen as a layerwise adversarial training in latent space from the first layer to the last layer, with the attack space of each latent space replaced with a convex relaxed version.</span></mark></p></li></ul><p><span>NAS + defense</span></p><ul><li><p><em><span>Minghao Guo, Yuzhe Yang, Rui Xu, Ziwei Liu, Dahua Lin. When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks. CVPR 2020. </span><a href='https://arxiv.org/abs/1911.10695'><strong><span>arXiv:1911.10695</span></strong></a></em></p><p><mark><span>They design a NAS to search for the most robust architecture and discover that a dense network is more robust.</span></mark></p></li></ul><p><span>Defense at Inference</span></p><ul><li><p><em><span>Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, Nate Kushman. PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples. ICLR 2018. </span><strong><a href='https://arxiv.org/abs/1710.10766'><span> arXiv:1710.10766</span></a></strong></em><span>  (</span><strong><span>PixelDefend</span></strong><span>)</span></p><p><mark><span>They propose to purify the adversarial example before feeding it to the model by projecting adversarial examples back to the data manifold, i.e. restore the data distribution, using a Pixel CNN. It was breached and labeled as obfuscated gradient later.</span></mark></p></li><li><p><em><span>Tianyu Pang, Kun Xu, Jun Zhu.  Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks. ICLR 2020. </span><strong><span>Paper: </span><a href='https://openreview.net/forum?id=ByxtC2VtPB' target='_blank' class='url'>https://openreview.net/forum?id=ByxtC2VtPB</a></strong></em><span>  (</span><strong><span>MI</span></strong><span>)</span></p><p><mark><span>They analyze mixup as a defense in inference, i.e. choosing a clean example and mix it (weighted sum) with the fed example (potentially adversarial), and conclude that it is an effective defense given the assumption that the network functions linearly between instances. It works well along with Interpolate Adversarial Training.</span></mark></p></li></ul><p><span>Ensemble</span></p><ul><li><p><em><span>Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel. Ensemble Adversarial Training: Attacks and Defenses. ICLR 2018. </span><a href='https://arxiv.org/abs/1705.07204'><span> </span><strong><span>arXiv:1705.07204</span></strong></a></em><span> (</span><strong><span>R+FGSM ensemble</span></strong><span>)</span></p><p><mark><span>They propose an ensemble adversarial training with single step attack started from random points.</span></mark></p></li><li><p><em><span>Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li. DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles. NIPS 2020. </span><a href='https://arxiv.org/abs/2009.14720'><strong><span>arXiv:2009.14720</span></strong></a></em></p></li></ul><p><span>Breach Defense</span></p><ul><li><em><span>Warren He, James Wei, Xinyun Chen, Nicholas Carlini, Dawn Song. Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong. arXiv preprint 2017. </span><strong><a href='https://arxiv.org/abs/1706.04701'><span> arXiv:1706.04701</span></a></strong></em></li><li><em><span>Nicholas Carlini, David Wagner. Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods. AISec 2017. </span><strong><a href='https://arxiv.org/abs/1705.07263'><span> arXiv:1705.07263</span></a></strong></em></li><li><em><span>Anish Athalye, Nicholas Carlini, David Wagner. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. ICML 2018. </span><strong><a href='http://export.arxiv.org/abs/1802.00420'><span> arXiv:1802.00420</span></a></strong></em></li></ul><p><span>Evaluation</span></p><ul><li><em><span>Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, Alexey Kurakin. On Evaluating Adversarial Robustness. </span><a href='https://arxiv.org/abs/1902.06705'><strong><span>arXiv:1902.06705</span></strong></a></em><span> (</span><mark><span>SINGLE NOTE</span></mark><span>) </span><code>LIVING DOCUMENT</code></li></ul><h2><a name="explanation" class="md-header-anchor"></a><span>Explanation</span></h2><p><span>This direction germinates from the robustness analysis of machine learning algorithms, which is a domain with a long history.</span></p><p><a href="Note-AdversarialExplanation.html" target="_blank"><span>Explanation of Robustness and Adversarial Example</span></a></p><p><span>Robustness Analysis</span></p><ul><li><p><em><span>Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard. Robustness of classifiers: from adversarial to random noise. NIPS 2016.</span></em><span> </span><strong><em><a href='https://arxiv.org/abs/1608.08967'><span> arXiv:1608.08967</span></a></em></strong></p></li><li><p><em><span>Alhussein Fawzi, Hamza Fawzi, Omar Fawzi. Adversarial vulnerability for any classifier. NIPS 2018.</span></em><span> </span><strong><em><span>Paper: </span><a href='http://papers.nips.cc/paper/7394-adversarial-vulnerability-for-any-classifier' target='_blank' class='url'>http://papers.nips.cc/paper/7394-adversarial-vulnerability-for-any-classifier</a></em></strong><span> (</span><mark><span>Single NOTE</span></mark><span>)</span></p><p><mark><span>They combine a generator and a discriminator to analyze the adversarial vulnerability and give the relation between in-distribution robustness (defined as the magnitude of smallest perturbation inside the data distribution, it&#39;s actually a measure of generalization) and unconstrained robustness (adversarial robustness). They also give an upper bound of the robustness.</span></mark></p></li><li><p><em><span>Daniel Cullina, Arjun Nitin Bhagoji, Prateek Mittal. PAC-learning in the presence of evasion adversaries. NIPS 2018. </span><a href='https://arxiv.org/abs/1806.01471'><span> </span><strong><span>arXiv:1806.01471</span></strong></a></em><span> (</span><mark><span>SINGLE NOTE</span></mark><span>)</span></p><p><mark><span>They evaluate the sample complexity in the frame of PAC-learning theory, concluding that the sample complexity with the presence of adversary can be smaller, similar or larger than that of a standard scenario.</span></mark></p><p><mark><span>Not very useful for engineers.</span></mark></p></li><li><p><em><span>Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard, Stefano Soatto. Robustness of Classifiers to Universal Perturbations: A Geometric Perspective. ICLR 2018.</span></em><span>  (*)</span></p></li><li><p><em><span>Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, Aleksander Madry. Adversarially Robust Generalization Requires More Data. NIPS 2018. </span><a href='https://arxiv.org/abs/1804.11285'><strong><span>arXiv:1804.11285</span></strong></a></em></p><p><mark><span>They discover that in adversarial training there appears overfitting in CIFAR-10  but not in MNIST. They further study a Bernoulli model, which is similar to MNIST and find that using  partial binarization (thresholding) can effectively improve the defense against adversarial attack in MNIST.</span></mark></p><p><mark><span>They also experiment the relationship between training set size and robust accuarcy and conclude that a larger training set size is always better for the same level of perturbation. To reach the same level of robust accuracy, a larger training set size is required for a larger perturbation allowed. Hence they conclude that adversarially robust generalization requires more data.</span></mark></p></li><li><p><em><span>Carl-Johann Simon-Gabriel, Yann Ollivier, Léon Bottou, Bernhard Schölkopf, David Lopez-Paz. First-order Adversarial Vulnerability of Neural Networks and Input Dimension. ICML 2019. </span><strong><a href='https://arxiv.org/abs/1802.01421'><span> arXiv:1802.01421</span></a></strong></em><span> (</span><mark><span>SINGLE NOTE</span></mark><span>)</span></p><p><mark><span>They prove that when the perturbation is small such that the loss objective can be approximated by its first-order taylor expansion, adversarial training is equivalent to regularize the dual norm of gradient with respect to the norm used for perturbation. In the case of </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.746ex" height="2.331ex" viewBox="0 -791.2 751.6 1003.7" role="img" focusable="false" style="vertical-align: -0.493ex;"><defs><path stroke-width="0" id="E16-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E16-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E16-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E16-MJMAIN-32" x="421" y="-213"></use></g></svg></span><script type="math/tex">l_2</script><span>-norm, they build a link with the </span><em><span>double backpropagation</span></em><span> proposed decasdes ago in the purpose of increasing accuracy.</span></mark></p><p><mark><span>They also illustrate that with the current initialization of weights that reserves the variance from layer to layer makes the adversarial vulnerability increases like </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.149ex" height="2.82ex" viewBox="0 -1001.7 1356 1214.1" role="img" focusable="false" style="vertical-align: -0.493ex;"><defs><path stroke-width="0" id="E17-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path stroke-width="0" id="E17-MJMAIN-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E17-MJMAIN-221A" x="0" y="62"></use><rect stroke="none" width="523" height="60" x="833" y="802"></rect><use xlink:href="#E17-MJMATHI-64" x="833" y="0"></use></g></svg></span><script type="math/tex">\sqrt{d}</script><span> with respect to the input dimension </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.215ex" height="2.087ex" viewBox="0 -791.2 523 898.4" role="img" focusable="false" style="vertical-align: -0.249ex;"><defs><path stroke-width="0" id="E18-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E18-MJMATHI-64" x="0" y="0"></use></g></svg></span><script type="math/tex">d</script><span> . They argue that for the model to be robust to any type of </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.75ex" height="2.698ex" viewBox="0 -791.2 753.7 1161.5" role="img" focusable="false" style="vertical-align: -0.86ex;"><defs><path stroke-width="0" id="E19-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E19-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E19-MJMATHI-70" x="421" y="-213"></use></g></svg></span><script type="math/tex">l_p</script><span> attack, the average absolute value of the coefficients of gradient should grow slower than </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.537ex" height="2.698ex" viewBox="0 -843.8 1523 1161.5" role="img" focusable="false" style="vertical-align: -0.738ex;"><defs><path stroke-width="0" id="E20-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E20-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path stroke-width="0" id="E20-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E20-MJMAIN-31" x="0" y="0"></use><use xlink:href="#E20-MJMAIN-2F" x="500" y="0"></use><use xlink:href="#E20-MJMATHI-64" x="1000" y="0"></use></g></svg></span><script type="math/tex">1/d</script><span>.</span></mark></p><p><mark><span>Empirically, they also show that proper gradient regularization can match with adversarial augmentation. They also show that as the error rate drops in the whole training process, the adversarial error rate first drops then grows, and PGD adversarial training outperforms down-sampling.</span></mark></p></li><li><p><em><span>Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, Aleksander Madry. Robustness May Be at Odds with Accuracy. ICLR 2019. </span><strong><a href='https://arxiv.org/abs/1805.12152'><span> arXiv:1805.12152</span></a></strong></em></p><p><mark><span>They prove that a very strong adversary can flip the data distribution, hence hindering the adversarial training. They also show that the gradients of adversarially trained model are more interpretable.</span></mark></p></li></ul><p><span>What is Adversarial Example? </span></p><ul><li><p><em><span>Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S. Schoenholz, Maithra Raghu, Martin Wattenberg, Ian Goodfellow. The Relationship Between High-Dimensional Geometry and Adversarial Examples.  arXiv preprint 2018. </span><strong><a href='https://arxiv.org/abs/1801.02774v3'><span>arXiv:1801.02774v3</span></a></strong></em></p></li><li><p><em><span>Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander Madry. Adversarial examples are not bugs, they are features. NIPS 2019.</span></em><span> </span><strong><em><a href='https://arxiv.org/abs/1905.02175v3'><span>arXiv:1905.02175v3</span></a></em></strong></p><p><mark><span>They discover that it&#39;s possible to train a relatively robust model with standard training using the features utilized by a robust model; respectively, it&#39;s also possible to train a very accurate but highly non-robust model using the dataset crafted in a manner that only the non-robust feature utilized by a classifier is related to the label.</span></mark></p><p><mark><span>Therefore, they conclude that adversarial examples are not bugs, they are features.</span></mark></p></li><li><p><em><span>Nic Ford, Justin Gilmer, Nicolas Carlini, Dogus Cubuk. Adversarial Examples Are a Natural Consequence of Test Error in Noise.  arXiv preprint 2019 </span><a href='https://arxiv.org/abs/1901.10513'><span> </span><strong><span>arXiv:1901.10513</span></strong></a></em></p><p><mark><span>They use a halfspace model to demonstrate that when the Gaussian noise error rate is relative low, there is still likely to exist an inperceptible adversarial example. They also use the Gaussian isoperimetric inequality to show that the best boundary with the least number of adversarially attackable points should be linear.</span></mark></p></li></ul><h2><a name="interpretaion" class="md-header-anchor"></a><span>Interpretaion</span></h2><p><span>These are some empirical discoveries and some unique interpretations for adversarial examples and the robustness of models.</span></p><p><a href="Note-AdversarialInterpretation.html" target="_blank"><span>Interprertation for Robustness and Adversarial Example</span></a></p><ul><li><p><em><span>Dong Yin, Raphael Gontijo Lopes, Jonathon Shlens, Ekin D. Cubuk, Justin Gilmer. A Fourier Perspective on Model Robustness in Computer Vision. NIPS 2019. </span><strong><a href='https://arxiv.org/abs/1906.08988'><span> arXiv:1906.08988</span></a></strong></em></p><p><mark><span>They observe that adversarially robust model focus more on the low-frequency component as well as model trained with Gaussian augmentation and they both suffer from low-frequency corruptions such as fog. They also observe that adding certain Fourier basis vector with large norm can craft adversarial example.</span></mark></p></li><li><p><em><span>Tianyuan Zhang, Zhanxing Zhu. Interpreting Adversarially Trained Convolutional Neural Networks. ICML 2019. </span><a href='https://arxiv.org/abs/1905.09797'><span> </span><strong><span>arXiv:1905.09797</span></strong></a></em></p><p><mark><span>They empirically show that adversarially trained network focuses more on the shape information rather than texture, and points out that potentially one can enhance the robustness of model by forcing it focus more on global features. This can partially explain the performance of feature denoising.</span></mark></p></li><li><p><em><span>Cihang Xie, Alan Yuille. Intriguing Properties of Adversarial Training at Scale. ICLR 2020.</span></em><span> </span><strong><em><span>Paper: </span><a href='https://openreview.net/forum?id=HyxJhCEFDS&amp;noteId=rJxeamAAKB' target='_blank' class='url'>https://openreview.net/forum?id=HyxJhCEFDS&noteId=rJxeamAAKB</a></em></strong></p><p><mark><span>They discover that Batch Normalization has a negative effect on robustness and observe that although standard accuracy increases marginally as the depth of model grows, the robust accuracy increases significantly.</span></mark></p></li><li><p><em><span>Shivam Garg, Vatsal Sharan, Brian Hu Zhang, Gregory Valiant. A Spectral View of Adversarially Robust Features. NIPS 2018. </span><a href='https://arxiv.org/abs/1811.06609'><span> </span><strong><span>arXiv:1811.06609</span></strong></a></em><span> (*)</span></p></li><li><p><em><span>Leslie Rice, Eric Wong, J. Zico Kolter. Overfitting in adversarially robust deep learning. arXiv preprint 2020 </span><strong><a href='https://arxiv.org/abs/2002.11569'><span> arXiv:2002.11569</span></a></strong></em><span> (</span><strong><span>AT with PGD + Early Stop</span></strong><span>)</span></p><p><mark><span>They observe that overfitting occurs in adversarial training although not yet in standard training, therefore they propose to early stop the adversarial training, which surprisingly reaches the SOTA results.</span></mark></p></li></ul><h2><a name="benchmark" class="md-header-anchor"></a><span>Benchmark</span></h2><p><span>These are some benchmark datasets and some methods proposed to benchmark the performance.</span></p><p><a href="Note-AdversarialBenchmark.html" target="_blank"><span>Benchmark Adversarial Defenses</span></a></p><ul><li><p><em><span>Dan Hendrycks, Thomas G. Dietterich. Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations. ICLR 2019. </span><strong><a href='https://arxiv.org/abs/1807.01697'><span> arXiv:1807.01697</span></a></strong></em><span> (</span><strong><span>ImageNet-C and ImageNet-P</span></strong><span>)</span></p><p><mark><span>They propose two corrupted ImageNet dataset, ImageNet-C with multiple corruptions and ImageNet-P with perturbations with various magnitudes.</span></mark></p></li><li><p><em><span>Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Nicolas Flammarion, Mung Chiang, Prateek Mittal, Matthias Hein. RobustBench: a standardized adversarial robustness benchmark. ICLR 2020. </span><strong><a href='https://arxiv.org/abs/2010.09670'><span> arXiv:2010.09670</span></a></strong></em><span> (</span><strong><span>Robustbench</span></strong><span>)</span></p><p><mark><span>They propose to use autoattack to benchmark the performance of different defense methods, and create a leaderboard.</span></mark></p></li><li><p><em><span>Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song. Natural Adversarial Examples. arXiv preprint 2020.</span><strong><a href='https://arxiv.org/abs/1907.07174'><span> arXiv:1907.07174</span></a></strong></em><span> (</span><strong><span>ImageNet-A and ImageNet-O</span></strong><span>)</span></p><p><mark><span>They point out the existence of natural adversarial examples, i.e. those examples are naturally easy to be misclassified and craft the ImageNet-A.</span></mark></p></li><li><p><em><span>Francesco Croce, Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. ICML 2020. </span><strong><a href='https://arxiv.org/abs/2003.01690'><span> arXiv:2003.01690</span></a></strong></em><span> (</span><strong><span>AutoAttack</span></strong><span>)</span></p></li></ul><h2><a name="false-positive-noise" class="md-header-anchor"></a><span>False positive noise</span></h2><p><span>Images that are meaningless to human eyes, but meaningful to classifiers.</span></p><ul><li><em><span>Anh Nguyen, Jason Yosinski, Jeff Clune. Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images. CVPR 2015. </span><a href='https://arxiv.org/abs/1412.1897'><strong><span>arXiv:1412.1897</span></strong></a></em><span> (*)</span></li></ul><h2><a name="adversarial-augmentation" class="md-header-anchor"></a><span>Adversarial augmentation</span></h2><p><span>This is a very fresh direction with potential to grow up.</span></p><p><a href="Note-AdversarialAugmentation.html" target="_blank"><span>Adversarial Augmentation</span></a></p><ul><li><p><em><span>Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan Yuille, Quoc V. Le. Adversarial Examples Improve Image Recognition. CVPR 2020. </span><a href='https://arxiv.org/abs/1911.09665v2'><strong><span>arXiv:1911.09665v2</span></strong></a></em></p><p><mark><span>They use an independent Batch Normalization branch to incorparate adversarial examples for a better accuracy.</span></mark></p></li></ul><hr /><div id="floating" style="z-index: 9999; position: fixed ! important; left: 10px; top: 10px;">
<span width="100%" style="position: absolute; width:20px; left: 0px; top: 0px;">
<a class="md-toc-inner" href="#content" style="text-decoration:none;" title="Top">
<font size="3em">🔝</font>
</a>
</span>
</div></div>
</body>
</html>