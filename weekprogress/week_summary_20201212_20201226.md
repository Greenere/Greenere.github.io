# Summary - 2020.12.12~2020.12.26

By LI Haoyang 2020.12.26

[TOC]

## Notes

- <a href="https://zhuanlan.zhihu.com/p/337880063" target="_blank">对抗正则化——盲人摸象还是对症下药？</a>
- <a href="../blogs/pages/Note-AdversarialLabelSmoothing.html" target="_blank">Adversarial Label Smoothing and Logit Squeezing</a>
- <a href="../blogs/pages/Single-InductiveBias.html" target="_blank">Higher-level Inductive Biases</a>
- <a href="../blogs/pages/Note-AdversarialRegularization.html" target="_blank">Adversarial Defense by Regularization</a> `UPDATED`
- <a href="../blogs/pages/Note-AdversarialTraining2.html" target="_blank">Advances along Adversarial Training - 2</a> `UPDATED`
- <a href="../blogs/pages/Concept-Channel.html" target="_blank">The Channel in Convolutional Neural Nets</a> `THOUGHTS`

## Paper reviewed (6)

### Adversarial Logit Regularization

- [x] *Ali Shafahi, Amin Ghiasi, Furong Huang, Tom Goldstein. Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training? arXiv preprint 2019. [**arXiv:1910.11585**](https://arxiv.org/abs/1910.11585)* `ICLR 2019 WITHDRAWAL`
- [x] *Cecilia Summers, Michael J. Dinneen. Improved Adversarial Robustness via Logit Regularization Methods. arXiv preprint 2019. [**arXiv:1906.03749**](https://arxiv.org/abs/1906.03749)* `ICLR 2019 WITHDRAWAL`
- [x] *Morgane Goibert, Elvis Dohmatob. Adversarial Robustness via Label-Smoothing. arXiv preprint 2019. **[ arXiv:1906.11567](https://arxiv.org/abs/1906.11567)***
- [x] *Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein, Dietrich Klakow. Logit Pairing Methods Can Fool Gradient-Based Attacks. NIPS 2018 workshop. **[ arXiv:1810.12042](https://arxiv.org/abs/1810.12042)***
- [x] *Logan Engstrom, Andrew Ilyas, Anish Athalye. Evaluating and Understanding the Robustness of Adversarial Logit Pairing. NIPS SECML 2018. **[ arXiv:1807.10272](https://arxiv.org/abs/1807.10272)***

### Perspective Articles

- [x] *Anirudh Goyal, Yoshua Bengio. Inductive Biases for Deep Learning of Higher-Level Cognition. arXiv preprint 2020. [**arXiv:2011.15091**](https://arxiv.org/abs/2011.15091)* (==SINGL NOTE==)

### Unfinished

- [ ] *I. Kobyzev, S. Prince and M. Brubaker, "Normalizing Flows: An Introduction and Review of Current Methods," in IEEE Transactions on Pattern Analysis and Machine Intelligence, doi: 10.1109/TPAMI.2020.2992934.*
- [ ] *Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard. Optimism in the Face of Adversity: Understanding and Improving Deep Learning through Adversarial Robustness. arXiv preprint 2020. **[ arXiv:2010.09624](https://arxiv.org/abs/2010.09624)***

## Experiments

### Uncertain Classifier

The following methods are explored for training a classifier with uncertainty, details are in experiment report:

- Casual Learning (not causal learning)
- Logit Regularization
- Hacking Cross Entropy Loss

The results are very interesting from my perspective.

### Classifier with Memory

The structure of a classifier combined with memory and generator is tested, which is very interesting and effective on MNIST, but not working on CIFAR-10.

The structure is very interesting, I believe with more configurations, it can work.

### Channel and Auto-Encoder

A simple theoretical analysis is done for the setting of channel number for convolutional neural networks.

A definition and analysis of the adversarial robustness of auto-encoder is done, which has not been studied in literature  yet (perhaps due to its simplicity; there are many works about variational auto-encoder that is significantly different).

The best channel number for a shallow auto-encoder is explored, details are in experiment report.