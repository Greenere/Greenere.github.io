# Summary - 2020.12.26~2021.1.10

By LI Haoyang 2021.1.10

[TOC]

## Notes

- <a href="blogs/pages/Single-NormalizingFlow.html" target="_blank">Normalizing Flow</a>
- <a href="blogs/pages/Single-OptimismAdversity.html" target="_blank">Optimism at the Face of Adversity</a>

- <a href="blogs/pages/Note-AdversarialDefenseInference.html" target="_blank">Adversarial Defense at Inference</a> `UPDATED`
- <a href="blogs/pages/Note-AdversarialAttackRestricted.html" target="_blank">Restricted Adversarial Attacks</a> `UPDATED`

## Paper Reviewed (4)

- [x]  *I. Kobyzev, S. Prince and M. Brubaker, "Normalizing Flows: An Introduction and Review of Current Methods," in IEEE Transactions on Pattern Analysis and Machine Intelligence, doi: 10.1109/TPAMI.2020.2992934.* (==SINGLE NOTE==)
- [x]  *Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard. Optimism in the Face of Adversity: Understanding and Improving Deep Learning through Adversarial Robustness. arXiv preprint 2020. **[arXiv:2010.09624](https://arxiv.org/abs/2010.09624)*** (==SINGLE NOTE==)
- [x]  *Yuping Lin, Kasra Ahmadi K. A., Hui Jiang.  Neural Networks Against Adversarial Attacks. arXiv preprint 2019. **[ arXiv:1905.12797](https://arxiv.org/abs/1905.12797)***
- [x]  *Anish Athalye, Logan Engstrom, Andrew Ilyas, Kevin Kwok. Synthesizing Robust Adversarial Examples. ICML 2018. **[ arXiv:1707.07397](https://arxiv.org/abs/1707.07397)***

## Experiments

Several methods of noise modulation are tested, they appears to be very interesting.

It's for sure that with noise modulation, the model learned a more robust representation, but not robust enough to defend adversarial attack effectively.

It's interesting that with fewer noise, the mimicking modulation appears to recover the performance of adversarial training super efficiently. Details are in experimental report.

