# Summary - 2020.11.15~2020.11.27

By LI Haoyang 2020.11.27

[TOC]

## Notes

- <a href="../blogs/pages/Note-AdversarialExplanation1.html" target="_blank">Explanation of Robustness and Adversarial Example - 1</a> `updated`
- <a href="../blogs/pages/Note-AdversarialExplanation2.html" target="_blank">Explanation of Robustness and Adversarial Example - 2</a> `branched`
- <a href="../blogs/pages/Note-AdversarialTraining1.html" target="_blank">Adversarial Defense by Adversarial Training - 1</a> `updated`
- <a href="../blogs/pages/Note-AdversarialTraining2.html" target="_blank">Adversarial Defense by Adversarial Training - 2</a> `branched`
- <a href="../blogs/pages/Note-AdversarialDefenseEnsemble.html" target="_blank">Adversarial Defense with Ensemble</a> `updated`
- <a href="../blogs/pages/Single-AdversarialVulnerabilityFirstorder.html" target="_blank">First-order  Adversarial Vulnerability</a> 
- <a href="../blogs/pages/Single-AdversarialTrainingTricks.html" target="_blank">Bag of Tricks for Adversarial Training</a> 
- <a href="../blogs/pages/Single-ShortcutLearning.html" target="_blank">Shortcut Learning as a Concept</a> 
- <a href="../blogs/pages/Note-NeuralNetworkInterpretation.html" target="_blank">Interpretation of Neural Networks</a>

## Paper reviewed (13)

### Adversarial Learning

 `DEFENSE` `ATTACK` `EXPLANATION`

- [x] *Carl-Johann Simon-Gabriel, Yann Ollivier, Léon Bottou, Bernhard Schölkopf, David Lopez-Paz. First-order Adversarial Vulnerability of Neural Networks and Input Dimension. ICML 2019. **[ arXiv:1802.01421](https://arxiv.org/abs/1802.01421)*** (==SINGLE NOTE==)
- [x] *Amirreza Shaeiri, Rozhin Nobahari, Mohammad Hossein Rohban. Towards Deep Learning Models Resistant to Large Perturbations. arXiv preprint 2020. [ **arXiv:2003.13370**](https://arxiv.org/abs/2003.13370)*
- [x] *Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel. Ensemble Adversarial Training: Attacks and Defenses. ICLR 2018. [ **arXiv:1705.07204**](https://arxiv.org/abs/1705.07204)* (**R+FGSM ensemble**)
- [x] *Colin Wei, Tengyu Ma. Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin. ICLR 2020.* ***Paper: https://openreview.net/forum?id=HJe_yR4Fwr***
- [x] *Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard. Hold me tight! Influence of discriminative features on deep network boundaries. NIPS 2020. **[ arXiv:2002.06349](https://arxiv.org/abs/2002.06349)***
- [x] *Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi, Percy Liang. Understanding and Mitigating the Tradeoff Between Robustness and Accuracy. ICML 2020. [ **arXiv:2002.10716**](https://arxiv.org/abs/2002.10716)*
- [x] *Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu. Bag of Tricks for Adversarial Training. arXiv preprint 2020. **[ arXiv:2010.00467](https://arxiv.org/abs/2010.00467)*** (==SINGLE NOTE==)
- [ ] *Morgane Goibert, Elvis Dohmatob. Adversarial Robustness via Label-Smoothing. arXiv preprint 2019. **[ arXiv:1906.11567](https://arxiv.org/abs/1906.11567)***

### Interpretation of Deep Learning

`LEARNING PROCESS` `TRICKS`

- [x] *Haohan Wang, Xindi Wu, Pengcheng Yin, Eric P. Xing. High-frequency Component Helps Explain the Generalization of Convolutional Neural Networks. CVPR 2020. **[ arXiv:1905.13545](https://arxiv.org/abs/1905.13545)***
- [x] *Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals. Understanding deep learning requires rethinking generalization. ICLR 2017. [ **arXiv:1611.03530**](http://export.arxiv.org/abs/1611.03530)*
- [x] *Rafael Müller, Simon Kornblith, Geoffrey Hinton. When Does Label Smoothing Help? NIPS 2019. **[ arXiv:1906.02629](https://arxiv.org/abs/1906.02629)***

### Tricks

- [x] *Dániel Varga, Adrián Csiszárik, Zsolt Zombori. Gradient Regularization Improves Accuracy of Discriminative Models. arXiv preprint 2018. **[ arXiv:1712.09936](https://arxiv.org/abs/1712.09936)***

### Perspective Article

- [x] *Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A. Wichmann. Shortcut Learning in Deep Neural Networks. arXiv preprint 2020. **[ arXiv:2004.07780](https://arxiv.org/abs/2004.07780)***

## Expriments

- Confirmation of the reported performance in ***Bag of Tricks for Adversarial Training***
- Setup of a robustness test bench based on PGD attack