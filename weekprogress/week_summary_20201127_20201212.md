# Summary - 2020.11.27~2020.12.12

By LI Haoyang 2020.12.12

[TOC]

## Notes

- <a href="https://zhuanlan.zhihu.com/p/296809584">对抗训练——终极数据增强？</a>

- <a href="../blogs/pages/Single-AdversarialInevitable.html" target="_blank">Are Adversarial Example Inevitable?</a>
- <a href="../blogs/pages/Single-FeaturePurification.html" target="_blank">Feature Purification : an Explanation for Adversarial Training</a>
- <a href="../blogs/pages/Note-AdversarialExplanation2.html" target="_blank">Explanation of Robustness and Adversarial Example - 2</a> `updated`
- <a href="../blogs/pages/Note-AdversarialAugmentation.html" target="_blank">Adversarial Augmentation</a> `updated`
- <a href="../blogs/pages/Single-InvertibleResNet.html" target="_blank">Invertible Residual Network</a>
- <a href="../blogs/pages/Note-AdversarialAttackRestricted.html" target="_blank">Restricted Adversarial Attacks</a>
- <a href="../blogs/pages/Note-AdversarialGenerative.html" target="_blank">Adversarial and Generative</a>

## Paper reviewed (11)

### Adversarial Attack & Defense

- [x] *Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi. One pixel attack for fooling deep neural networks. CVPR 2017. **[ arXiv:1710.08864](https://arxiv.org/abs/1710.08864)***

    ==One-pixel attack demonstrating the surprising vulnerability.==

- [x] *Chuan Guo, Jared S. Frank, Kilian Q. Weinberger. Low Frequency Adversarial Perturbation. UAI 2019. **[ arXiv:1809.08758](https://arxiv.org/abs/1809.08758)***

    ==Low frequency restriction for better black-box attacks.==

- [x] *Yash Sharma, Gavin Weiguang Ding, Marcus Brubaker. On the Effectiveness of Low Frequency Perturbations. IJCAI 2019. **[ arXiv:1903.00073](https://arxiv.org/abs/1903.00073)***

    ==Complete evaluation of low frequency perturbations.==

- [x] *Lukas Schott, Jonas Rauber, Matthias Bethge, Wieland Brendel. Towards the first adversarially robust neural network model on MNIST. arXiv preprint 2018. **[ arXiv:1805.09190](https://arxiv.org/abs/1805.09190)***

    ==Use generative Bayesian classifiers for robust classfication.==

### Adversarial Learning

- [x] *Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan Engstrom, Aleksander Madry. Image Synthesis with a Single (Robust) Classifier. arXiv preprint 2019  [ **arXiv:1906.09453**](https://arxiv.org/abs/1906.09453)*

    ==Re-purpose adversarially trained model for generative applications.==

- [x] *Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Aleksander Madry. Adversarial Robustness as a Prior for Learned Representations. arXiv preprint 2019. **[ arXiv:1906.00945](https://arxiv.org/abs/1906.00945)***

    ==Demonstrate the generalizable representations learned by robust classifier.==

- [x] *Jörn-Henrik Jacobsen, Jens Behrmann, Richard Zemel, Matthias Bethge. Excessive Invariance Causes Adversarial Vulnerability. ICLR 2019. **[ arXiv:1811.00401](https://arxiv.org/abs/1811.00401)***

    ==Propose an complementary adversarial example caused by excessive invariance rather than excessive sensitivity.==

- [x] *Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry. Do Adversarially Robust ImageNet Models Transfer Better? arXiv preprint 2020. **[ arXiv:2007.08489](https://arxiv.org/abs/2007.08489)***

    ==Demonstrate the improved transferability of adversarially trained classifier.==

- [x] *Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom Goldstein. Are adversarial examples inevitable? ICLR 2019. **[ arXiv:1809.02104](https://arxiv.org/abs/1809.02104)***

    ==Theoretical analysis for the existence of adversarial example.==

- [x] *Zeyuan Allen-Zhu, Yuanzhi Li. Feature Purification: How Adversarial Training Performs Robust Deep Learning. arXiv preprint 2020. **[ arXiv:2005.10190](https://arxiv.org/abs/2005.10190)***

    ==Theoretical explanation for the vulnerability of standard training and the learning process of adversarial training.==

### Invertible  Neural Networks

- [x] *Jens Behrmann, Will Grathwohl, Ricky T. Q. Chen, David Duvenaud, Jörn-Henrik Jacobsen. Invertible Residual Networks. ICML 2019. **[ arXiv:1811.00995](https://arxiv.org/abs/1811.00995)***

    ==Make the residual network invertible by  spectral normalization and weight scaling.==

## Experiments

- Experiments for hypothesis